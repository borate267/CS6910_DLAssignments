{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "final_q6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c08cb285bd2d461586c7219e9e92b8a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e7b6c71385b44007802cec1cc6227bdc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e002d3a41f7f4b14a768b2c9a78b6899",
              "IPY_MODEL_6484343e27d941fea91e2bfe32f69f30"
            ]
          }
        },
        "e7b6c71385b44007802cec1cc6227bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e002d3a41f7f4b14a768b2c9a78b6899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_16610e3ed92746f6b04808dc0dc2cb7b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed5fc0e802ca43619bd9e1a1e11e9bcb"
          }
        },
        "6484343e27d941fea91e2bfe32f69f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_42f144ef004f44ffb445ee374b2dd1b9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 46/46 [17:07&lt;00:00, 22.34s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ce5c95da952d41f894e793a1c5be4083"
          }
        },
        "16610e3ed92746f6b04808dc0dc2cb7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ed5fc0e802ca43619bd9e1a1e11e9bcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42f144ef004f44ffb445ee374b2dd1b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ce5c95da952d41f894e793a1c5be4083": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9ZhrUeTDsx-"
      },
      "source": [
        "from random import randint\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "import keras.backend as K\n",
        "from tensorflow.keras import models\n",
        "from numpy import array_equal\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, SimpleRNN, GRU\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "from tensorflow.keras.layers import RepeatVector\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "import io\n",
        "!pip install imageio imageio -ffmpeg\n",
        "!pip install tqdm\n",
        "\n",
        "tf.keras.backend.set_floatx('float64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx0oFPzV5vpB",
        "outputId": "71d7d05b-54e0-43ba-c47c-599e59805c5e"
      },
      "source": [
        "!git clone https://github.com/borate267/lexicon-dataset.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'lexicon-dataset' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENHB62dRqM2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99f81a92-ffa4-436f-b4b2-141209880b32"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUI8eRZepQex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "466bb501-aca6-4c96-acd5-0bc1ea19f617"
      },
      "source": [
        "import wget\n",
        "wget.download('https://tamil.indiatyping.com/images/downloadfonts/Tamil/vijaya.zip')\n",
        "!unzip /content/vijaya.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/vijaya.zip\n",
            "replace vijaya/india typing.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an0uSRI_xQOl"
      },
      "source": [
        "from matplotlib.font_manager import FontProperties\n",
        "tamil_font = FontProperties(fname = '/content/vijaya/vijaya.ttf') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBzvL2e20Sx-",
        "outputId": "847bd234-c57e-4bf6-b564-d4765ef0bf7e"
      },
      "source": [
        "train_dir = \"lexicon-dataset/ta.translit.sampled.train.tsv\"\n",
        "dev_dir = \"lexicon-dataset/ta.translit.sampled.dev.tsv\"\n",
        "test_dir = \"lexicon-dataset/ta.translit.sampled.test.tsv\"\n",
        "\n",
        "# The following function reads the raw text document and returns a list of lists comprising the romanized and native versions of the words\n",
        "\n",
        "def read_corpus(corpus_file):\n",
        "  tamil_words = []\n",
        "  latin_words = []\n",
        "  with io.open(corpus_file, encoding ='utf-8') as f:\n",
        "    for line in f:\n",
        "      if '\\t' not in line:\n",
        "        continue\n",
        "      tokens = line.rstrip().split(\"\\t\")\n",
        "      latin_words.append(tokens[1])\n",
        "      tamil_words.append(tokens[0])\n",
        "  return latin_words, tamil_words\n",
        "\n",
        "train_source, train_target = read_corpus(train_dir)\n",
        "valid_source, valid_target = read_corpus(dev_dir)\n",
        "test_source, test_target = read_corpus(test_dir)\n",
        "\n",
        "print(\"Number of training samples: \", len(train_source))\n",
        "print(\"Number of validation samples: \", len(valid_source))\n",
        "print(\"Number of testing samples: \", len(test_source))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples:  68218\n",
            "Number of validation samples:  6827\n",
            "Number of testing samples:  6864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgxYhZkv53Rl",
        "outputId": "9cce37af-24ff-4785-fdca-be513fda184d"
      },
      "source": [
        "arr = np.arange(len(train_source))\n",
        "np.random.shuffle(arr)\n",
        "arr1 = np.arange(len(valid_source))\n",
        "np.random.shuffle(arr1)\n",
        "\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "input_texts_ns = []\n",
        "target_texts_ns = []\n",
        "val_input_texts_ns = []\n",
        "val_target_texts_ns = []\n",
        "\n",
        "for (input_text, target_text) in zip(train_source, train_target):\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"B\" + target_text + \"E\"\n",
        "    input_texts_ns.append(input_text)\n",
        "    target_texts_ns.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "for (input_text, target_text) in zip(valid_source, valid_target):\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"B\" + target_text + \"E\"\n",
        "    val_input_texts_ns.append(input_text)\n",
        "    val_target_texts_ns.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "\n",
        "for i in range(len(train_source)):\n",
        "    input_texts.append(input_texts_ns[arr[i]])\n",
        "    target_texts.append(target_texts_ns[arr[i]])\n",
        "\n",
        "val_input_texts = []\n",
        "val_target_texts = []\n",
        "\n",
        "for i in range(len(valid_source)):\n",
        "    val_input_texts.append(val_input_texts_ns[arr1[i]])\n",
        "    val_target_texts.append(val_target_texts_ns[arr1[i]])\n",
        "\n",
        "input_characters.add(\" \")\n",
        "target_characters.add(\" \")\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "\n",
        "\n",
        "\n",
        "# Adding the padding character\n",
        "#input_characters.append(\"P\")\n",
        "#target_characters.append(\"P\")\n",
        "\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "val_max_encoder_seq_length = max([len(txt) for txt in val_input_texts])\n",
        "val_max_decoder_seq_length = max([len(txt) for txt in val_target_texts])\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "print(\"Max sequence length for val inputs:\", val_max_encoder_seq_length)\n",
        "print(\"Max sequence length for val outputs:\", val_max_decoder_seq_length)\n",
        "\n",
        "print(input_characters)\n",
        "print(target_characters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 68218\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 49\n",
            "Max sequence length for inputs: 30\n",
            "Max sequence length for outputs: 28\n",
            "Max sequence length for val inputs: 23\n",
            "Max sequence length for val outputs: 22\n",
            "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "[' ', 'B', 'E', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ', 'ஊ', 'எ', 'ஏ', 'ஐ', 'ஒ', 'ஓ', 'க', 'ங', 'ச', 'ஜ', 'ஞ', 'ட', 'ண', 'த', 'ந', 'ன', 'ப', 'ம', 'ய', 'ர', 'ற', 'ல', 'ள', 'ழ', 'வ', 'ஷ', 'ஸ', 'ஹ', 'ா', 'ி', 'ீ', 'ு', 'ூ', 'ெ', 'ே', 'ை', 'ொ', 'ோ', 'ௌ', '்']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtHaPQPw6VuP",
        "outputId": "06928226-764f-4a5d-ee29-32f3ed9b48f7"
      },
      "source": [
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "reverse_source_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "print(input_token_index)\n",
        "print(target_token_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
            "{' ': 0, 'B': 1, 'E': 2, 'ஃ': 3, 'அ': 4, 'ஆ': 5, 'இ': 6, 'ஈ': 7, 'உ': 8, 'ஊ': 9, 'எ': 10, 'ஏ': 11, 'ஐ': 12, 'ஒ': 13, 'ஓ': 14, 'க': 15, 'ங': 16, 'ச': 17, 'ஜ': 18, 'ஞ': 19, 'ட': 20, 'ண': 21, 'த': 22, 'ந': 23, 'ன': 24, 'ப': 25, 'ம': 26, 'ய': 27, 'ர': 28, 'ற': 29, 'ல': 30, 'ள': 31, 'ழ': 32, 'வ': 33, 'ஷ': 34, 'ஸ': 35, 'ஹ': 36, 'ா': 37, 'ி': 38, 'ீ': 39, 'ு': 40, 'ூ': 41, 'ெ': 42, 'ே': 43, 'ை': 44, 'ொ': 45, 'ோ': 46, 'ௌ': 47, '்': 48}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtAojV-O6p0G"
      },
      "source": [
        "trunc_input_texts = input_texts[:68096]\n",
        "trunc_target_texts = target_texts[:68096]\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(trunc_input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float64\"\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(trunc_input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float64\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(trunc_input_texts, trunc_target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_target_data[i, t, target_token_index[char]] = 1.0\n",
        "    decoder_target_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    \n",
        "val_encoder_input_data = np.zeros(\n",
        "    (len(val_input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float64\"\n",
        ")\n",
        "val_decoder_target_data = np.zeros(\n",
        "    (len(val_target_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float64\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(val_input_texts, val_target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        val_encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    #encoder_input_data[i, t + 1 :] = input_token_index[\"P\"]\n",
        "    val_encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "\n",
        "    for t, char in enumerate(target_text):\n",
        "      # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        val_decoder_target_data[i, t, target_token_index[char]] = 1.0\n",
        "    val_decoder_target_data[i, t + 1: ,target_token_index[\" \"]] = 1.0\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx8rEIqmMQNT"
      },
      "source": [
        "# ATTENTION MECHANISM "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-RyyRhTQ2XC"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "    \n",
        "  def call(self, query, values):\n",
        "    \n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "    \n",
        "    \n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "    return context_vector, attention_weights\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYLhbKsxt3EH"
      },
      "source": [
        "#import tensorflow \n",
        "class LuongAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(LuongAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "   \n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "    \n",
        "    values_transposed = tf.transpose(values, perm=[0, 2, 1])\n",
        "    \n",
        "    #LUONGH Dot-product\n",
        "    score = tf.transpose(tf.matmul(query_with_time_axis, values_transposed) , perm=[0, 2, 1])\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mfk2-afoCeE"
      },
      "source": [
        "class MyRNN_atten(object):\n",
        "  def __init__(self,cell_type = 'RNN', hidden_size=32, \n",
        "               learning_rate= 1e-3,dropout=0.3,epochs = 10, batch_size = 32,\n",
        "               attention = 'bahdanau'):\n",
        "    \n",
        "    self.cell_type = cell_type\n",
        "    self.hidden_size = hidden_size\n",
        "    self.learning_rate = learning_rate\n",
        "    self.dropout = dropout\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.attention = attention\n",
        "\n",
        "  def build_fit(self,encoder_input_data,decoder_target_data):\n",
        "\n",
        "    encoder_inputs = Input(shape=(max_encoder_seq_length, num_encoder_tokens), name='encoder_inputs')\n",
        "    if self.cell_type == 'LSTM':\n",
        "      encoder_lstm = LSTM(self.hidden_size,return_sequences=True, return_state=True, dropout = self.dropout, name='encoder_lstm')\n",
        "      encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(encoder_inputs)\n",
        "      encoder_states = [encoder_state_h, encoder_state_c]\n",
        "    elif self.cell_type == 'GRU':\n",
        "      encoder_gru = GRU(self.hidden_size,return_sequences=True, return_state=True, dropout = self.dropout, name='encoder_gru')\n",
        "      encoder_outputs, encoder_state_h = encoder_gru(encoder_inputs)\n",
        "      encoder_states = [encoder_state_h]\n",
        "    elif self.cell_type == 'RNN':\n",
        "      encoder_rnn = SimpleRNN(self.hidden_size,return_sequences=True, return_state=True, dropout = self.dropout, name='encoder_rnn')\n",
        "      encoder_outputs, encoder_state_h = encoder_rnn(encoder_inputs)\n",
        "      encoder_states = [encoder_state_h]\n",
        "\n",
        "    # Set up the attention layer\n",
        "    if self.attention == 'bahdanau':\n",
        "      attention= BahdanauAttention(self.hidden_size)\n",
        "    elif self.attention == 'luong':\n",
        "      attention= LuongAttention(self.hidden_size)\n",
        "\n",
        "    # Set up the decoder layers\n",
        "    decoder_inputs = Input(shape=(1, (num_decoder_tokens+self.hidden_size)),name='decoder_inputs')\n",
        "    if self.cell_type == 'LSTM':\n",
        "      decoder_lstm = LSTM(self.hidden_size, dropout = self.dropout, return_state=True, name='decoder_lstm')\n",
        "    elif self.cell_type == 'GRU':\n",
        "      decoder_gru = GRU(self.hidden_size, dropout = self.dropout, return_state=True, name='decoder_gru')\n",
        "    elif self.cell_type == 'RNN':\n",
        "      decoder_rnn = SimpleRNN(self.hidden_size, dropout = self.dropout, return_state=True, name='decoder_rnn')  \n",
        "    \n",
        "    decoder_dense = Dense(num_decoder_tokens, activation='softmax',  name='decoder_dense')\n",
        "\n",
        "    all_outputs = []\n",
        "\n",
        "    inputs = np.zeros((self.batch_size, 1, num_decoder_tokens))\n",
        "    inputs[:, 0, 0] = 1 \n",
        "\n",
        "    decoder_outputs = encoder_state_h\n",
        "    states = encoder_states\n",
        "\n",
        "    for _ in range(max_decoder_seq_length):\n",
        "\n",
        "      context_vector, attention_weights=attention(decoder_outputs, encoder_outputs)\n",
        "      \n",
        "      context_vector = tf.expand_dims(context_vector, 1)\n",
        "      \n",
        "      inputs = tf.concat([context_vector, inputs], axis=-1)\n",
        "      if self.cell_type == 'LSTM':\n",
        "        decoder_outputs, state_h, state_c = decoder_lstm(inputs, initial_state=states)\n",
        "      if self.cell_type == 'GRU':\n",
        "        decoder_outputs, state_h = decoder_gru(inputs, initial_state=states)\n",
        "      if self.cell_type == 'RNN':\n",
        "        decoder_outputs, state_h = decoder_rnn(inputs, initial_state=states)\n",
        "      \n",
        "      outputs = decoder_dense(decoder_outputs)\n",
        "      outputs = tf.expand_dims(outputs, 1)\n",
        "      all_outputs.append(outputs)\n",
        "      inputs = outputs\n",
        "      if self.cell_type == 'LSTM':\n",
        "        states = [state_h, state_c]\n",
        "      if self.cell_type == 'GRU' or self.cell_type == 'RNN':\n",
        "        states = [state_h]\n",
        "\n",
        "\n",
        "    decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
        "    #getindicelayer = Lambda(lambda x: x[:, -1, :]) \n",
        "    #decoder_outputs = getindicelayer(all_outputs)\n",
        "\n",
        "    model = Model(encoder_inputs, decoder_outputs, name='model_encoder_decoder')\n",
        "    \n",
        "    optimizer = Adam(lr=self.learning_rate, beta_1=0.9, beta_2=0.999)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    #model.summary()\n",
        "\n",
        "    model.fit(encoder_input_data, decoder_target_data,\n",
        "              batch_size=self.batch_size, \n",
        "              epochs=self.epochs,\n",
        "              )\n",
        "    if self.cell_type == 'LSTM':\n",
        "      return encoder_lstm,attention,decoder_lstm,decoder_dense\n",
        "    if self.cell_type == 'GRU':\n",
        "      return encoder_gru,attention,decoder_gru,decoder_dense\n",
        "    if self.cell_type == 'RNN':\n",
        "      return encoder_rnn,attention,decoder_rnn,decoder_dense  \n",
        "    \n",
        "  def evaluate(self,seq_in):\n",
        "    attention_plot = np.zeros((max_decoder_seq_length, max_encoder_seq_length))\n",
        "    #sequence = [7, 9, 8, 5]\n",
        "    sequence = seq_in\n",
        "    #sequence = one_hot_encode(seq_in,num_encoder_tokens)\n",
        "    encoder_inputs=array(sequence).reshape(1,max_encoder_seq_length,num_encoder_tokens)\n",
        "    \n",
        "    encoder_inputs = tf.convert_to_tensor(encoder_inputs,dtype=tf.float32)\n",
        "    \n",
        "    if self.cell_type == 'LSTM':\n",
        "      #encoder_lstm = LSTM(self.hidden_size,return_sequences=True, return_state=True, dropout = self.dropout, name='encoder_lstm')\n",
        "      encoder_outputs, encoder_state_h, encoder_state_c = encoder(encoder_inputs)\n",
        "      encoder_states = [encoder_state_h, encoder_state_c]\n",
        "    elif self.cell_type == 'GRU':\n",
        "      #encoder_gru = GRU(self.hidden_size,return_sequences=True, return_state=True, dropout = self.dropout, name='encoder_gru')\n",
        "      encoder_outputs, encoder_state_h = encoder(encoder_inputs)\n",
        "      encoder_states = [encoder_state_h]\n",
        "    elif self.cell_type == 'RNN':\n",
        "      #encoder_rnn = SimpleRNN(self.hidden_size,return_sequences=True, return_state=True, dropout = self.dropout, name='encoder_rnn')\n",
        "      encoder_outputs, encoder_state_h = encoder(encoder_inputs)\n",
        "      encoder_states = [encoder_state_h]\n",
        "\n",
        "    all_outputs = []\n",
        "\n",
        "    decoder_input_data = np.zeros((1, 1, num_decoder_tokens))\n",
        "    decoder_input_data[:, 0, 0] = 1 \n",
        "\n",
        "    inputs = decoder_input_data\n",
        "    decoder_outputs = encoder_state_h\n",
        "    states = encoder_states\n",
        "\n",
        "    weigh_atten =[]\n",
        "    for t in range(max_decoder_seq_length):\n",
        "\n",
        "      # pay attention\n",
        "      context_vector, attention_weights = attention(decoder_outputs, encoder_outputs)\n",
        "\n",
        "      # storing the attention weights to plot later on\n",
        "      attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "      weigh_atten.append(attention_weights)\n",
        "      \n",
        "      attention_plot[t] = attention_weights.numpy()\n",
        "      \n",
        "      decoder_outputs=tf.expand_dims(decoder_outputs, 1)\n",
        "\n",
        "      context_vector = tf.expand_dims(context_vector, 1)\n",
        "      inputs = tf.concat([context_vector, inputs], axis=-1)\n",
        "\n",
        "      if self.cell_type == 'LSTM':\n",
        "        decoder_outputs, state_h, state_c = decoder(inputs, initial_state=states)\n",
        "      if self.cell_type == 'GRU':\n",
        "        decoder_outputs, state_h = decoder(inputs, initial_state=states)\n",
        "      if self.cell_type == 'RNN':\n",
        "        decoder_outputs, state_h = decoder(inputs, initial_state=states)\n",
        "            \n",
        "      outputs = decoder_dense(decoder_outputs)\n",
        "      # Store the current prediction (we will concatenate all predictions later)\n",
        "      outputs = tf.expand_dims(outputs, 1)\n",
        "      all_outputs.append(outputs)\n",
        "      inputs = outputs\n",
        "      if self.cell_type == 'LSTM':\n",
        "        states = [state_h, state_c]\n",
        "      if self.cell_type == 'GRU' or self.cell_type == 'RNN':\n",
        "        states = [state_h]\n",
        "    \n",
        "    decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
        "    seq_outs = decoder_outputs[0]\n",
        "    seq_out = tf.argmax(seq_outs, axis=1)\n",
        "    seq_out = seq_out.numpy()\n",
        "    seq_in = tf.argmax(seq_in, axis = 1)\n",
        "    seq_in = seq_in.numpy()\n",
        "    list(filter(lambda num: num != 0, seq_in))\n",
        "    list(filter(lambda num: num != 0, seq_out))\n",
        "    \n",
        "    return seq_in, seq_out, attention_plot, weigh_atten\n",
        "\n",
        "  def plot_attention(self,attention, sequence, predicted_sequence):\n",
        "    fig = plt.figure(figsize=(3,3))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 80}\n",
        "    seq = ''\n",
        "    for i in range(len(sequence)):\n",
        "      seq = seq + reverse_source_char_index[sequence[i]]\n",
        "    \n",
        "    pred = ''\n",
        "    for i in range(len(predicted_sequence)):\n",
        "      pred = pred + reverse_target_char_index[predicted_sequence[i]]\n",
        "\n",
        "    #ax.rcParams[\"font.family\"] = \"Vijaya\"\n",
        "    ax.set_xticklabels(seq, fontdict=fontdict)\n",
        "    ax.set_yticklabels(pred, fontdict=fontdict, fontproperties = tamil_font)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "  def translate(self,seq_in):\n",
        "    seq_in, seq_out, attention_plot, weigh_atten = self.evaluate(seq_in)\n",
        "\n",
        "    a = [0]\n",
        "    for i in range(len(seq_in)):\n",
        "      if seq_in[i] != 0:\n",
        "        a.append(seq_in[i])\n",
        "\n",
        "    b = []\n",
        "    for i in range(len(seq_out)):\n",
        "      if seq_out[i] != 0:\n",
        "        b.append(seq_out[i])\n",
        "  \n",
        "    b = b[:len(b)-1]\n",
        "    print(a)\n",
        "    print(b)\n",
        "    \n",
        "    attention_plot = attention_plot[:len(b), :len(a)]\n",
        "    self.plot_attention(attention_plot, a, b)  \n",
        "\n",
        "    return weigh_atten\n",
        "\n",
        "  def attention_plot(self,val_input):\n",
        "    seq_in = val_input\n",
        "    weigh_atten = self.translate(seq_in)  \n",
        "    return weigh_atten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H8C__mqymd-"
      },
      "source": [
        "model_rnn = MyRNN_atten(cell_type = 'LSTM', hidden_size=128, learning_rate= 1e-3,\n",
        "                        dropout=0.2,epochs = 15, batch_size = 128, attention = 'bahdanau')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2iRrBYTEoCh"
      },
      "source": [
        "encoder,attention,decoder,decoder_dense = model_rnn.build_fit(encoder_input_data,decoder_target_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB36aNtQuBwh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "e972c304-367b-4de8-f90c-783c16983575"
      },
      "source": [
        "w_a = model_rnn.attention_plot(val_encoder_input_data[6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 20, 8, 15, 12, 12, 9, 25, 1, 12]\n",
            "[1, 22, 45, 30, 48, 30, 38, 27, 30, 48]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdgAAAHZCAYAAAAlhSo8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAU10lEQVR4nO3df7DldX3f8dd7d6/LjxAxgCmUIWCEUqT+SG6NJumYlJJRZ1pjG9MhbajNhDWpzMRmMJlkJo3pH+m0Yy2R+qObtNJ2qETD0GlIf0xoSZqKvzZR0aIhYkW0RsIPQfmxu6yf/nEvnZ0dF+7dc977vd+7j8fMHXbPuef7fQ0L+9zvOefurTFGAIDl2jH1AADYjgQWABoILAA0EFgAaCCwANBAYAGggcAeZ1X1e1X1L6fesd1V1fVVdcvUOzZiTluT+e2lh/8OntmuqQcsS1X9XpJPjTGunnoLbHM/k6SmHgFb3bYJLHB8jDEennoDzMG2eIq4qq5P8ookb6yqsf5x/qSjnt6OqvrVqrq/qu6rqrdW1Zb8taiq3VV1bVV9paqeqKoPVdX3T72L6Wz1pwar6sqqeqCqdh9x+w1V9Z+m2vV0quqVVfUHVfVQVT1YVf+tqv7i1LtYzJb8Tf0Y/EySDyZ5T5Kz1z/unXTR0/s7SZ5M8r1Jrk7ypiR/e9JFR/fPsrbtJ5K8JMknk/zXqjp70lVwdO/P2u9tr3nqhqp6dpLXJvnXU416BqcmuTbJS5P8QJKHk/x2VT1rylEsZlsEdv0pqwNJHhtj/On6x6Gpdz2NO8cY/2iMcdcY431Jbkty2dSjjlRVpyb56SQ/P8b4nTHGp5P8VJKvJHnjpOPgKMYYjye5IWt/KHzKjyV5JMnvTDLqGYwxblr/+JMxxh1J/n6SC7IWXGZqWwR2hu444uf/N8lzpxjyDL4zyUqSDzx1w/ofXD6Y5JKpRsEG/HqSy6vq3PWf/0SSfzvGeHLCTUdVVd9ZVf+hqu6uqkey9ofYHUnOm3gaCxDYaRw84ucj8/u18G2Y2LLGGJ9I8kdJXl9VlyZZTfJvpl31tG5JclaSNyT5nqy9HPNkEk8Rz9jcflN/OgeS7Jx6xDZzd9b+vX7fUzdU1c4kL09y51SjYIN+Pcnrk/xkkg+MMf542jnfXFWdkeTiJL86xrh1/aWY0+KrPGZvOwX280leWlXnV9WZW/VduXMyxng0ybuS/NOqevX6uxrfleTbk7xz0nHwzN6b5M9l7X0EW/XNTUnyUJL7k1xVVc+vqlckeXfWrmCZse0Uobdm7WrrziR/Fq9dLMvPJ/nNrL1D++NJXpjklWOML0+6Cp7BGONrSd6XZP/6P7ekMcY3svZO/Rcm+VSSdyT5paztZsZqDC+lAdtTVf2XJF8cY1w19RZOPJ7jB7adqnpOkr+S5IeSvGjiOZygBBbYjj6W5NuS/OIY41NTj+HE5CliAGiwnd7kBABbhsACQINtF9iq2jP1ho2a09ZkXnvntDWZ1945bU3mtXdOW5N57Z1i67YLbJLZ/IJnXluTee2d09ZkXnvntDWZ1945bU3mtVdgAWA7mOxdxCefftI47ZxTl37cxx96Iic/56SlHnP/51aWerynHDj0eJ618+SlH3es9PyVzAcOPppnrSz51+zrjy/3eOsOZn9WsvuZP3GLmNPeOW1N5rV3TluTee3t2vq1PHT/GOOsb3bfZF8He9o5p+ZH/v2rpjr9pnzuinOmnrApB//86VNP2LAdv/+xqScAHLNbx2/dc7T7PEUMAA0EFgAaCCwANBBYAGggsADQQGABoIHAAkADgQWABgILAA0EFgAaCCwANBBYAGggsADQQGABoIHAAkADgQWABgILAA0EFgAa7FrGQarqLyT5V0fc/JtjjHct4/gAMDdLCWySv5zk6iQXJ3nTGOP7l3RcAJilZT1FfGGSzyR5cZKPH+2TqmpPVe2rqn2PP/TEkk4NAFvPQlewVXVSkt9K8i1JXpG1wH65qu5I8vfGGB87/PPHGHuT7E2S515yxljk3ACwlS16BXtGkjvGGD+Q5JVJ9if5m0n+XZJfWvDYADBbCwV2jPGlJF+sqv+e5ANJ/vkY49NJzkryyBL2AcAsLfwmpzHGO5O8M0mq6qyq+tkkVyS5bNFjA8BcLfoa7Muz9uU5DyYZSR5I8qEkl44xXMECcMJa9Ar2byT50BhjzzLGAMB2sWhg353knGUMAYDtZKHAjjHuSXLPkrYAwLbh7yIGgAYCCwANBBYAGggsADQQWABoILAA0EBgAaCBwAJAA4EFgAYCCwANBBYAGggsADRY+BuuH6snPjPy2Zcfmur0m1K7vjz1hE353f9589QTNuxVz//eqSdsyjcee2zqCcBMuIIFgAYCCwANBBYAGggsADQQWABoILAA0EBgAaCBwAJAA4EFgAYCCwANBBYAGggsADQQWABoILAA0EBgAaCBwAJAA4EFgAbHFNiq2llVz1n2GADYLjYV2Ko6r6rel+TRJA9W1T1V9cM90wBgvjYc2Kr6jiS3JflkkkuSnJLk9UneWlXf1bIOAGZq1yY+9+1JXj/G+IPDbrutqn40yS8ked1SlwHAjG0osFV1YZJPHxHXJMkY44+qatf65317kn+Q5KEk5yWpJB8cY7xveZMBYOvb6FPEL01yc5JU1d+qqluq6gcPu//ewz7vP44xrk1ydpIvHB7XqtpTVfuqat/BsX8J8wFga9poYJ+V5OtVdUqSV2Xttdd/XGt2Zu2KNUkuTfK/13/84iQfO/wgY4y9Y4zVMcbqSu1eeDwAbFUbDeydSf5qkpUk94wx7k9yIMmZSV6wfn+S7B5jHFgP8YVJPr7kvQAwCxsK7Bjjw1m7cv1rSc6tqr+e5KIk92ftaeGPHnG8Fyb54hjjq8udCwDzsJl3Ef90khuTvCzJa5L83THGqKrnjTF+o6rOSPLA+ue+OK5eATiBbTiwY4x7kry8qr41ydfGGGP99l9c/+cDSX5t/cfvTvLu5c8FgHnYzBVskmSM8UjHEADYTvxl/wDQQGABoIHAAkADgQWABgILAA0EFgAaCCwANBBYAGggsADQQGABoIHAAkADgQWABgILAA0EFgAabPrb1S3NSMaTT052+s0Yhw5NPWFTXvmaH596woZ99le+ZeoJm7L7wZp6woad+09un3oCnNBcwQJAA4EFgAYCCwANBBYAGggsADQQWABoILAA0EBgAaCBwAJAA4EFgAYCCwANBBYAGggsADQQWABoILAA0EBgAaCBwAJAA4EFgAYCCwANBBYAGiwU2Ko6tareXFU3VdWNVXXZ+u27q+q+qrpoOTMBYF6OObBVdV6S9ybZl+TKJG9Lcn1VXT7G2J/k2iSvPuIxe6pqX1XtO5j9C8wGgK1tkSvYa5JcNca4bYzx6BjjI0luTHL5+v1vT3L64Q8YY+wdY6yOMVZXsnuBUwPA1rZIYA8kWamqW6vq7qq6NMn5Se5av//iJJ9ZcB8AzNIigX04yRVJ3pLk80leluQFSe6tqpUkb0hy84L7AGCWdi3w2OuSvCfJ1UluT3JDkpOTvCPJF5Jcs/5aLACccI45sGOMryZ57RE3X7f+AQAnNF8HCwANBBYAGggsADQQWABoILAA0EBgAaCBwAJAA4EFgAYCCwANBBYAGggsADQQWABoILAA0EBgAaCBwAJAg0W+4fqJY4ypF2zOx/946gUbdtH/OW3qCZvyo//rk1NP2LD3X/9dU0/YlCe//KdTT9i4qqkXbM7cfg/bJlzBAkADgQWABgILAA0EFgAaCCwANBBYAGggsADQQGABoIHAAkADgQWABgILAA0EFgAaCCwANBBYAGggsADQQGABoIHAAkCDlsBW1e6qur2qfrnj+ACw1XVdwe5McnaSs5qODwBb2q6Og44xHktyQcexAWAOvAYLAA0EFgAatDxFfDRVtSfJniQ5Kaccz1MDwHF1XK9gxxh7xxirY4zVlew+nqcGgOPKU8QA0EBgAaCBwAJAA4EFgAYCCwANBBYAGggsADQQWABoILAA0EBgAaCBwAJAA4EFgAYCCwANBBYAGggsADQQWABoILAA0EBgAaCBwAJAg11TD2D5xsEDU0/YsEP3PzD1hE258dLzpp6wYd/2+/unnrApD77pL009YcN2PDqvf7eH7rxr6gknJFewANBAYAGggcACQAOBBYAGAgsADQQWABoILAA0EFgAaCCwANBAYAGggcACQAOBBYAGAgsADQQWABoILAA0EFgAaCCwANBAYAGggcACQAOBBYAGCwW2qk6tqjdX1U1VdWNVXbZ+++6quq+qLlrOTACYl2MObFWdl+S9SfYluTLJ25JcX1WXjzH2J7k2yauPeMyeqtpXVfsOZv8CswFga1vkCvaaJFeNMW4bYzw6xvhIkhuTXL5+/9uTnH74A8YYe8cYq2OM1ZXsXuDUALC1LRLYA0lWqurWqrq7qi5Ncn6Su9bvvzjJZxbcBwCztEhgH05yRZK3JPl8kpcleUGSe6tqJckbkty84D4AmKVdCzz2uiTvSXJ1ktuT3JDk5CTvSPKFJNesvxYLACecYw7sGOOrSV57xM3XrX8AwAnN18ECQAOBBYAGAgsADQQWABoILAA0EFgAaCCwANBAYAGggcACQAOBBYAGAgsADQQWABoILAA0EFgAaCCwANBgkW+4zla1Y+fUCzasVub1n+CO05899YQN+/CHnzf1hE0559wx9YQNO+VLUy/YnB2nnTb1hA37xte/PvWEzXma/2xdwQJAA4EFgAYCCwANBBYAGggsADQQWABoILAA0EBgAaCBwAJAA4EFgAYCCwANBBYAGggsADQQWABoILAA0EBgAaBBS2CrqjqOCwBzsdTAVtXVVXVfkoer6ueWeWwAmJOlBbaqXpjkJ5NcnuT7kryuql60rOMDwJws8wr22Ul+Y4zxiTHGJ5P8bJLvWeLxAWA2di3xWLdnLbJPeTjJQ0s8PgDMxtKuYMcYh8YYtxx200uSfGJZxweAOen8Mp0Lk/zJ4TdU1Z6q2ldV+w5mf+OpAWBanYHdMcYYh98wxtg7xlgdY6yuZHfjqQFgWl1fB7sryaGOYwPAHHRdwV6S5M6mYwPAlrfMdxH/f2OMO5Lc0XFsAJgDfxcxADQQWABoILAA0EBgAaCBwAJAA4EFgAYCCwANBBYAGggsADQQWABoILAA0EBgAaCBwAJAA4EFgAYCCwANBBYAGrR8w3Um9o1DUy/YsLF/PluT5NBX7pt6woZd+HMPTj1hc1588dQLNuyz/3Bl6gmbctFbzpp6wsadccHUCzbng+8/6l2uYAGggcACQAOBBYAGAgsADQQWABoILAA0EFgAaCCwANBAYAGggcACQAOBBYAGAgsADQQWABoILAA0EFgAaCCwANBAYAGggcACQAOBBYAGAgsADRYObFX9i6o6p6p+uKp+7LDbf7CqfmrR4wPAHC0U2Kp6bpI3JnkgyY8nOf2wu38kyTlHfP6eqtpXVfsOZv8ipwaALW3RK9jVJJ8aY+xf//EfHnbfdx/x84wx9o4xVscYqyvZveCpAWDrWjSw353kD6vqzKxdrX4iSapqV5IX5YjAAsCJYtHAnpvk8SQ/lOTOMcYT67dfkuSRMcYXFzw+AMzSrgUf/9tJrk/y/CSPVNVb128/O8l/XvDYADBbCwV2jHFLkjOXtAUAtg1fBwsADQQWABoILAA0EFgAaCCwANBAYAGggcACQAOBBYAGAgsADQQWABoILAA0EFgAaCCwANBAYAGggcACQINFv+E6sFXVvP78vOPuL009YcN2fu7iqSdsysMv2T31hA3b8eSYesLSzOv/QACYCYEFgAYCCwANBBYAGggsADQQWABoILAA0EBgAaCBwAJAA4EFgAYCCwANBBYAGggsADQQWABoILAA0EBgAaCBwAJAA4EFgAYCCwANBBYAGiwU2Ko6tareXFU3VdWNVXXZ+u27q+q+qrpoOTMBYF6OObBVdV6S9ybZl+TKJG9Lcn1VXT7G2J/k2iSvXspKAJiZRa5gr0ly1RjjtjHGo2OMjyS5Mcnl6/e/Pcnphz+gqvZU1b6q2ncw+xc4NQBsbYsE9kCSlaq6tarurqpLk5yf5K71+y9O8pnDHzDG2DvGWB1jrK5k9wKnBoCtbZHAPpzkiiRvSfL5JC9L8oIk91bVSpI3JLl5wX0AMEu7FnjsdUnek+TqJLcnuSHJyUnekeQLSa5Zfy0WAE44xxzYMcZXk7z2iJuvW/8AgBOar4MFgAYCCwANBBYAGggsADQQWABoILAA0EBgAaCBwAJAA4EFgAYCCwANBBYAGggsADQQWABoILAA0EBgAaCBwAJAg2P+huvA1jYOHph6wqYcemg+ey/4lY9OPWFTdlz0vKknbNiVN//u1BM25fabjn6fK1gAaCCwANBAYAGggcACQAOBBYAGAgsADQQWABoILAA0EFgAaCCwANBAYAGggcACQAOBBYAGAgsADQQWABoILAA0EFgAaNAS2KraXVW3V9UvdxwfALa6rivYnUnOTnJW0/EBYEvb1XHQMcZjSS7oODYAzIHXYAGgQcsV7NFU1Z4ke5LkpJxyPE8NAMfVcb2CHWPsHWOsjjFWV7L7eJ4aAI4rTxEDQAOBBYAGAgsADQQWABoILAA0EFgAaCCwANBAYAGggcACQAOBBYAGAgsADQQWABoILAA0EFgAaCCwANBAYAGggcACQAOBBYAGAgsADXZNPQAgSbJj59QLNmzHs7916gmbUzX1gg37hf/xuqknbNJHj3qPK1gAaCCwANBAYAGggcACQAOBBYAGAgsADQQWABoILAA0EFgAaCCwANBAYAGggcACQAOBBYAGAgsADQQWABoILAA0EFgAaCCwANBAYAGggcACQAOBBYAGAgsADXYdz5NV1Z4ke5LkpJxyPE8NAMfVcb2CHWPsHWOsjjFWV7L7eJ4aAI4rTxEDQAOBBYAGAgsADQQWABoILAA0EFgAaCCwANBAYAGggcACQAOBBYAGAgsADQQWABoILAA0EFgAaCCwANBAYAGggcACQAOBBYAGAgsADWqMMc2Jq/4syT0Nhz4zyf0Nx+0wp63JvPbOaWsyr71z2prMa++ctibz2tu19TvGGGd9szsmC2yXqto3xlidesdGzGlrMq+9c9qazGvvnLYm89o7p63JvPZOsdVTxADQQGABoMF2DOzeqQdswpy2JvPaO6etybz2zmlrMq+9c9qazGvvcd+67V6DBYCtYDtewQLA5AQWABoILAA0EFgAaCCwANDg/wEPwcH9ZScX0gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwHk7AfmgQGb"
      },
      "source": [
        "def cstr(s, color='black'):\n",
        "\tif s == ' ':\n",
        "\t\treturn \"<text style=color:#000;padding-left:10px;background-color:{}> </text>\".format(color, s)\n",
        "\telse:\n",
        "\t\treturn \"<text style=color:#000;background-color:{}>{} </text>\".format(color, s)\n",
        "\t\n",
        "# print html\n",
        "def print_color(t):\n",
        "\tdisplay(html_print(''.join([cstr(ti, color=ci) for ti,ci in t])))\n",
        "\n",
        "# get appropriate color for value\n",
        "def get_clr(value):\n",
        "\tcolors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8'\n",
        "\t\t'#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n",
        "\t\t'#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n",
        "\t\t'#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n",
        "\tvalue = int((value * 100) / 5)\n",
        "\treturn colors[value]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi1_bthXt_sL"
      },
      "source": [
        "from IPython.display import HTML as html_print\n",
        "from IPython.display import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPSYyRoseMSi",
        "outputId": "367f27a7-b549-491a-fdd4-47e9005d46df"
      },
      "source": [
        "#w_a = w_a\n",
        "print(np.shape(w_a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sUQVtFDis1-",
        "outputId": "f34e0e35-1e03-4c62-9e33-be0b509f3f04"
      },
      "source": [
        "eng = [16, 21, 20, 8, 20, 8, 1]\n",
        "tam = [25, 40, 22, 48, 22]\n",
        "\n",
        "eng_rev = ''\n",
        "for i in range(len(eng)):\n",
        "  eng_rev = eng_rev + reverse_source_char_index[eng[i]]\n",
        "\n",
        "tam_rev = ''\n",
        "for i in range(len(tam)):\n",
        "  tam_rev = tam_rev + reverse_target_char_index[tam[i]]\n",
        "\n",
        "print(eng_rev) \n",
        "print(tam_rev)\n",
        "\n",
        "len_eng = len(eng)\n",
        "len_tam = len(tam)\n",
        "print(len_eng)\n",
        "print(len_tam)\n",
        "\n",
        "for i in range(len(tam)):\n",
        "  print(reverse_target_char_index[tam[i]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "puththa\n",
            "புத்த\n",
            "7\n",
            "5\n",
            "ப\n",
            "ு\n",
            "த\n",
            "்\n",
            "த\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySjsQhyiiFWW"
      },
      "source": [
        "def visualize(output_values, result_list):\n",
        "  #print(\"\\nCell Number:\", cell_no, \"\\n\")\n",
        "  text_colours = []\n",
        "  for i in range(len_eng):\n",
        "    text = (result_list[i], get_clr(output_values[i]))\n",
        "    #text = (result_list, get_clr(output_values))  \n",
        "    text_colours.append(text)\n",
        "    if i == len_eng-1:\n",
        "      print_color(text_colours)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUW0qHO_iWEp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2c152404-1585-4cf0-b261-93c51446ac44"
      },
      "source": [
        "for j in range(len_tam):\n",
        "  visualize(w_a[j][:], eng_rev)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<text style=color:#000;background-color:#f68f8f>p </text><text style=color:#000;background-color:#baddee>u </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>h </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>h </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<text style=color:#000;background-color:#89c4e2>p </text><text style=color:#000;background-color:#f33b3b>u </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>h </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>h </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>p </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#baddee>t </text><text style=color:#000;background-color:#baddee>h </text><text style=color:#000;background-color:#eff7fb>t </text><text style=color:#000;background-color:#85c2e1>h </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>p </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#89c4e2>h </text><text style=color:#000;background-color:#f9bdbd>t </text><text style=color:#000;background-color:#99cce6>h </text><text style=color:#000;background-color:#95cae5>a </text>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>p </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>h </text><text style=color:#000;background-color:#95cae5>t </text><text style=color:#000;background-color:#a1d0e8#b2d9ec>h </text><text style=color:#000;background-color:#f9bdbd>a </text>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pboLXPhgeK-n",
        "outputId": "7046f67e-1c4a-4033-a87d-7094f6bd8e7a"
      },
      "source": [],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: fmpeg\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCGw6GgteP5o"
      },
      "source": [
        "import imageio\n",
        "import os   #This module provides a portable way of using operating system dependent functionality. \n",
        "from tqdm import tqdm_notebook as tqdm #used for progress bar in loops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I_V4iBfeTcK"
      },
      "source": [
        "#mention you video file name below\n",
        "clip = os.path.abspath('Boole.mov')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djnpNOJ-eWHr"
      },
      "source": [
        "def gifMaker(inputPath, targetFormat):\n",
        "    \n",
        "    #defining the output file name\n",
        "    outputPath = os.path.splitext(inputPath)[0] + targetFormat\n",
        "    \n",
        "    print(f'Converting {inputPath} \\n to {outputPath}')\n",
        "    \n",
        "    reader = imageio.get_reader(inputPath)\n",
        "    fps = reader.get_meta_data()['fps']\n",
        "    \n",
        "    writer = imageio.get_writer(outputPath, fps=fps)\n",
        "    \n",
        "    #for loop to append the frames in the video\n",
        "    for frames in tqdm(reader):\n",
        "        writer.append_data(frames)\n",
        "    \n",
        "    print ('Video Converted to GIF!')\n",
        "    writer.close"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "c08cb285bd2d461586c7219e9e92b8a7",
            "e7b6c71385b44007802cec1cc6227bdc",
            "e002d3a41f7f4b14a768b2c9a78b6899",
            "6484343e27d941fea91e2bfe32f69f30",
            "16610e3ed92746f6b04808dc0dc2cb7b",
            "ed5fc0e802ca43619bd9e1a1e11e9bcb",
            "42f144ef004f44ffb445ee374b2dd1b9",
            "ce5c95da952d41f894e793a1c5be4083"
          ]
        },
        "id": "iBom6I4seYF1",
        "outputId": "f413ee1b-3361-40d5-c4cf-5f6d429850a4"
      },
      "source": [
        "gifMaker(clip, '.gif')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting /content/Boole.mov \n",
            " to /content/Boole.gif\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c08cb285bd2d461586c7219e9e92b8a7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Video Converted to GIF!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}