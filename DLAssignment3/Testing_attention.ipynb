{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Testing_attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9ZhrUeTDsx-"
      },
      "source": [
        "from random import randint\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "import keras.backend as K\n",
        "from tensorflow.keras import models\n",
        "from numpy import array_equal\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, SimpleRNN, GRU\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "from tensorflow.keras.layers import RepeatVector\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "import io\n",
        "import csv\n",
        "\n",
        "tf.keras.backend.set_floatx('float64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx0oFPzV5vpB",
        "outputId": "4c56869a-23b9-4326-8daa-bb88487da87f"
      },
      "source": [
        "!git clone https://github.com/borate267/lexicon-dataset.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'lexicon-dataset'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 30 (delta 7), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (30/30), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBzvL2e20Sx-",
        "outputId": "e31e4674-35a1-4f68-f64c-acc38eb7eeff"
      },
      "source": [
        "train_dir = \"lexicon-dataset/ta.translit.sampled.train.tsv\"\n",
        "test_dir = \"lexicon-dataset/ta.translit.sampled.test.tsv\"\n",
        "\n",
        "# The following function reads the raw text document and returns a list of lists comprising the romanized and native versions of the words\n",
        "\n",
        "def read_corpus(corpus_file):\n",
        "  tamil_words = []\n",
        "  latin_words = []\n",
        "  with io.open(corpus_file, encoding ='utf-8') as f:\n",
        "    for line in f:\n",
        "      if '\\t' not in line:\n",
        "        continue\n",
        "      tokens = line.rstrip().split(\"\\t\")\n",
        "      latin_words.append(tokens[1])\n",
        "      tamil_words.append(tokens[0])\n",
        "  return latin_words, tamil_words\n",
        "\n",
        "train_source, train_target = read_corpus(train_dir)\n",
        "test_source, test_target = read_corpus(test_dir)\n",
        "\n",
        "print(\"Number of training samples: \", len(train_source))\n",
        "print(\"Number of testing samples: \", len(test_source))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples:  68218\n",
            "Number of testing samples:  6864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgxYhZkv53Rl",
        "outputId": "53f4a1d2-4d39-4622-8d4f-68e5edd522c6"
      },
      "source": [
        "arr = np.arange(len(train_source))\n",
        "np.random.shuffle(arr)\n",
        "arr1 = np.arange(len(test_source))\n",
        "np.random.shuffle(arr1)\n",
        "\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "input_texts_ns = []\n",
        "target_texts_ns = []\n",
        "test_input_texts_ns = []\n",
        "test_target_texts_ns = []\n",
        "\n",
        "for (input_text, target_text) in zip(train_source, train_target):\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"B\" + target_text + \"E\"\n",
        "    input_texts_ns.append(input_text)\n",
        "    target_texts_ns.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "for (input_text, target_text) in zip(test_source, test_target):\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"B\" + target_text + \"E\"\n",
        "    test_input_texts_ns.append(input_text)\n",
        "    test_target_texts_ns.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "\n",
        "for i in range(len(train_source)):\n",
        "    input_texts.append(input_texts_ns[arr[i]])\n",
        "    target_texts.append(target_texts_ns[arr[i]])\n",
        "\n",
        "test_input_texts = []\n",
        "test_target_texts = []\n",
        "\n",
        "for i in range(len(test_source)):\n",
        "    test_input_texts.append(test_input_texts_ns[arr1[i]])\n",
        "    test_target_texts.append(test_target_texts_ns[arr1[i]])\n",
        "\n",
        "input_characters.add(\" \")\n",
        "target_characters.add(\" \")\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "\n",
        "# Adding the padding character\n",
        "#input_characters.append(\"P\")\n",
        "#target_characters.append(\"P\")\n",
        "\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "test_max_encoder_seq_length = max([len(txt) for txt in test_input_texts])\n",
        "test_max_decoder_seq_length = max([len(txt) for txt in test_target_texts])\n",
        "\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "print(\"Max sequence length for val inputs:\", test_max_encoder_seq_length)\n",
        "print(\"Max sequence length for val outputs:\", test_max_decoder_seq_length)\n",
        "\n",
        "print(input_characters)\n",
        "print(target_characters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 68218\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 49\n",
            "Max sequence length for inputs: 30\n",
            "Max sequence length for outputs: 28\n",
            "Max sequence length for val inputs: 23\n",
            "Max sequence length for val outputs: 24\n",
            "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "[' ', 'B', 'E', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ', 'ஊ', 'எ', 'ஏ', 'ஐ', 'ஒ', 'ஓ', 'க', 'ங', 'ச', 'ஜ', 'ஞ', 'ட', 'ண', 'த', 'ந', 'ன', 'ப', 'ம', 'ய', 'ர', 'ற', 'ல', 'ள', 'ழ', 'வ', 'ஷ', 'ஸ', 'ஹ', 'ா', 'ி', 'ீ', 'ு', 'ூ', 'ெ', 'ே', 'ை', 'ொ', 'ோ', 'ௌ', '்']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtHaPQPw6VuP",
        "outputId": "9331ae27-9031-4b25-8725-0e7a31661bd5"
      },
      "source": [
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "reverse_source_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "print(input_token_index)\n",
        "print(target_token_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
            "{' ': 0, 'B': 1, 'E': 2, 'ஃ': 3, 'அ': 4, 'ஆ': 5, 'இ': 6, 'ஈ': 7, 'உ': 8, 'ஊ': 9, 'எ': 10, 'ஏ': 11, 'ஐ': 12, 'ஒ': 13, 'ஓ': 14, 'க': 15, 'ங': 16, 'ச': 17, 'ஜ': 18, 'ஞ': 19, 'ட': 20, 'ண': 21, 'த': 22, 'ந': 23, 'ன': 24, 'ப': 25, 'ம': 26, 'ய': 27, 'ர': 28, 'ற': 29, 'ல': 30, 'ள': 31, 'ழ': 32, 'வ': 33, 'ஷ': 34, 'ஸ': 35, 'ஹ': 36, 'ா': 37, 'ி': 38, 'ீ': 39, 'ு': 40, 'ூ': 41, 'ெ': 42, 'ே': 43, 'ை': 44, 'ொ': 45, 'ோ': 46, 'ௌ': 47, '்': 48}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtAojV-O6p0G"
      },
      "source": [
        "trunc_input_texts = input_texts[:68096]\n",
        "trunc_target_texts = target_texts[:68096]\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(trunc_input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float64\"\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(trunc_input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float64\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(trunc_input_texts, trunc_target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_target_data[i, t, target_token_index[char]] = 1.0\n",
        "    decoder_target_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    \n",
        "test_encoder_input_data = np.zeros(\n",
        "    (len(test_input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float64\"\n",
        ")\n",
        "test_decoder_target_data = np.zeros(\n",
        "    (len(test_target_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float64\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(test_input_texts, test_target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        test_encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    #encoder_input_data[i, t + 1 :] = input_token_index[\"P\"]\n",
        "    test_encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "\n",
        "    for t, char in enumerate(target_text):\n",
        "      # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        test_decoder_target_data[i, t, target_token_index[char]] = 1.0\n",
        "    test_decoder_target_data[i, t + 1: ,target_token_index[\" \"]] = 1.0\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx8rEIqmMQNT"
      },
      "source": [
        "# ATTENTION MECHANISM "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-RyyRhTQ2XC"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "    \n",
        "  def call(self, query, values):\n",
        "    \n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "    \n",
        "    \n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "    return context_vector, attention_weights\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYLhbKsxt3EH"
      },
      "source": [
        "#import tensorflow \n",
        "class LuongAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(LuongAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "   \n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "    \n",
        "    values_transposed = tf.transpose(values, perm=[0, 2, 1])\n",
        "    \n",
        "    #LUONGH Dot-product\n",
        "    score = tf.transpose(tf.matmul(query_with_time_axis, values_transposed) , perm=[0, 2, 1])\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mfk2-afoCeE"
      },
      "source": [
        "class MyRNN_atten(object):\n",
        "  def __init__(self,cell_type = 'RNN', hidden_size=32, \n",
        "               learning_rate= 1e-3,dropout=0.3,epochs = 10, batch_size = 32,\n",
        "               attention = 'bahdanau'):\n",
        "    \n",
        "    self.cell_type = cell_type\n",
        "    self.hidden_size = hidden_size\n",
        "    self.learning_rate = learning_rate\n",
        "    self.dropout = dropout\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.attention = attention\n",
        "\n",
        "  def build_fit(self,encoder_input_data,decoder_target_data):\n",
        "\n",
        "    encoder_inputs = Input(shape=(max_encoder_seq_length, num_encoder_tokens), name='encoder_inputs')\n",
        "    if self.cell_type == 'LSTM':\n",
        "      encoder_lstm = LSTM(self.hidden_size,return_sequences=True, return_state=True, dropout = self.dropout, name='encoder_lstm')\n",
        "      encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(encoder_inputs)\n",
        "      encoder_states = [encoder_state_h, encoder_state_c]\n",
        "    elif self.cell_type == 'GRU':\n",
        "      encoder_gru = GRU(self.hidden_size,return_sequences=True, return_state=True, dropout = self.dropout, name='encoder_gru')\n",
        "      encoder_outputs, encoder_state_h = encoder_gru(encoder_inputs)\n",
        "      encoder_states = [encoder_state_h]\n",
        "    elif self.cell_type == 'RNN':\n",
        "      encoder_rnn = SimpleRNN(self.hidden_size,return_sequences=True, return_state=True, dropout = self.dropout, name='encoder_rnn')\n",
        "      encoder_outputs, encoder_state_h = encoder_rnn(encoder_inputs)\n",
        "      encoder_states = [encoder_state_h]\n",
        "\n",
        "    # Set up the attention layer\n",
        "    if self.attention == 'bahdanau':\n",
        "      attention= BahdanauAttention(self.hidden_size)\n",
        "    elif self.attention == 'luong':\n",
        "      attention= LuongAttention(self.hidden_size)\n",
        "\n",
        "    # Set up the decoder layers\n",
        "    decoder_inputs = Input(shape=(1, (num_decoder_tokens+self.hidden_size)),name='decoder_inputs')\n",
        "    if self.cell_type == 'LSTM':\n",
        "      decoder_lstm = LSTM(self.hidden_size, dropout = self.dropout, return_state=True, name='decoder_lstm')\n",
        "    elif self.cell_type == 'GRU':\n",
        "      decoder_gru = GRU(self.hidden_size, dropout = self.dropout, return_state=True, name='decoder_gru')\n",
        "    elif self.cell_type == 'RNN':\n",
        "      decoder_rnn = SimpleRNN(self.hidden_size, dropout = self.dropout, return_state=True, name='decoder_rnn')  \n",
        "    \n",
        "    decoder_dense = Dense(num_decoder_tokens, activation='softmax',  name='decoder_dense')\n",
        "\n",
        "    all_outputs = []\n",
        "\n",
        "    inputs = np.zeros((self.batch_size, 1, num_decoder_tokens))\n",
        "    inputs[:, 0, 0] = 1 \n",
        "\n",
        "    decoder_outputs = encoder_state_h\n",
        "    states = encoder_states\n",
        "\n",
        "    for _ in range(max_decoder_seq_length):\n",
        "\n",
        "      context_vector, attention_weights=attention(decoder_outputs, encoder_outputs)\n",
        "      \n",
        "      context_vector = tf.expand_dims(context_vector, 1)\n",
        "      \n",
        "      inputs = tf.concat([context_vector, inputs], axis=-1)\n",
        "      if self.cell_type == 'LSTM':\n",
        "        decoder_outputs, state_h, state_c = decoder_lstm(inputs, initial_state=states)\n",
        "      if self.cell_type == 'GRU':\n",
        "        decoder_outputs, state_h = decoder_gru(inputs, initial_state=states)\n",
        "      if self.cell_type == 'RNN':\n",
        "        decoder_outputs, state_h = decoder_rnn(inputs, initial_state=states)\n",
        "      \n",
        "      outputs = decoder_dense(decoder_outputs)\n",
        "      outputs = tf.expand_dims(outputs, 1)\n",
        "      all_outputs.append(outputs)\n",
        "      inputs = outputs\n",
        "      if self.cell_type == 'LSTM':\n",
        "        states = [state_h, state_c]\n",
        "      if self.cell_type == 'GRU' or self.cell_type == 'RNN':\n",
        "        states = [state_h]\n",
        "\n",
        "\n",
        "    decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
        "    #getindicelayer = Lambda(lambda x: x[:, -1, :]) \n",
        "    #decoder_outputs = getindicelayer(all_outputs)\n",
        "\n",
        "    model = Model(encoder_inputs, decoder_outputs, name='model_encoder_decoder')\n",
        "    \n",
        "    optimizer = Adam(lr=self.learning_rate, beta_1=0.9, beta_2=0.999)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    #model.summary()\n",
        "\n",
        "    model.fit(encoder_input_data, decoder_target_data,\n",
        "              batch_size=self.batch_size, \n",
        "              epochs=self.epochs,\n",
        "              #callbacks = [WandbCallback()]\n",
        "              )\n",
        "    \n",
        "    global_total = 0\n",
        "    global_correct = 0\n",
        "    test_count = 6784\n",
        "\n",
        "    pred = model.predict(test_encoder_input_data[:test_count], batch_size = self.batch_size)\n",
        "\n",
        "    data_list = [[\"SNO\", \"Input Data\", \"Target Data\", \"Predicted Data\"]]\n",
        "\n",
        "    for index in range(0,test_count):\n",
        "      pred_vector = pred[index]\n",
        "      true_vector = test_decoder_target_data[index]\n",
        "      pred_indices = tf.argmax(pred_vector, axis=1)\n",
        "      true_indices = tf.argmax(true_vector, axis=1)\n",
        "\n",
        "      if (pred_indices.numpy() == true_indices.numpy()).all():\n",
        "        global_correct = global_correct + 1\n",
        "      \n",
        "      global_total = global_total + 1\n",
        "\n",
        "      arr = pred_indices.numpy()\n",
        "      decoded_sequence = ''\n",
        "      for i in range(1,len(arr)):\n",
        "        if arr[i] != 2:\n",
        "          decoded_sequence = decoded_sequence + reverse_target_char_index[arr[i]]\n",
        "\n",
        "      true_word = test_target_texts[index] \n",
        "      true_word = true_word[1:len(true_word)-1]\n",
        "      #print(true_word)\n",
        "      #print(decoded_sequence)\n",
        "      dlist = [index+1, test_input_texts[index], true_word, decoded_sequence]\n",
        "      data_list.append(dlist)\n",
        "\n",
        "    with open('predictions_attention.tsv', 'w', newline='') as file:\n",
        "      writer = csv.writer(file, delimiter='\\t')\n",
        "      writer.writerows(data_list)\n",
        "\n",
        "    val_accuracy = global_correct/global_total\n",
        "    print(val_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYNf5iRhCiAv"
      },
      "source": [
        "# BEST HYPERPARAMETERS\n",
        "\n",
        "best_attention = 'bahdanau'\n",
        "best_batch_size = 128\n",
        "best_cell_type = 'RNN'\n",
        "best_dropout = 0\n",
        "best_epochs = 20\n",
        "best_hidden_size = 128\n",
        "best_learning_rate = 0.001\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H8C__mqymd-"
      },
      "source": [
        "model_rnn = MyRNN_atten(cell_type = best_cell_type, hidden_size=best_hidden_size, learning_rate= best_learning_rate,\n",
        "                        dropout=best_dropout,epochs = best_epochs, batch_size = best_batch_size, attention = best_attention)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2iRrBYTEoCh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f20a79e-7c1e-4b86-c262-636bc8ff7258"
      },
      "source": [
        "model_rnn.build_fit(encoder_input_data,decoder_target_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "532/532 [==============================] - 52s 60ms/step - loss: 1.3523 - accuracy: 0.6689\n",
            "Epoch 2/20\n",
            "532/532 [==============================] - 32s 61ms/step - loss: 0.8321 - accuracy: 0.7436\n",
            "Epoch 3/20\n",
            "532/532 [==============================] - 32s 60ms/step - loss: 0.5252 - accuracy: 0.8403\n",
            "Epoch 4/20\n",
            "532/532 [==============================] - 32s 60ms/step - loss: 0.3607 - accuracy: 0.9077\n",
            "Epoch 5/20\n",
            "532/532 [==============================] - 32s 60ms/step - loss: 0.3069 - accuracy: 0.9235\n",
            "Epoch 6/20\n",
            "532/532 [==============================] - 32s 60ms/step - loss: 0.2830 - accuracy: 0.9291\n",
            "Epoch 7/20\n",
            "532/532 [==============================] - 32s 61ms/step - loss: 0.2657 - accuracy: 0.9334\n",
            "Epoch 8/20\n",
            "532/532 [==============================] - 32s 61ms/step - loss: 0.2646 - accuracy: 0.9331\n",
            "Epoch 9/20\n",
            "532/532 [==============================] - 32s 61ms/step - loss: 0.2438 - accuracy: 0.9388\n",
            "Epoch 10/20\n",
            "532/532 [==============================] - 32s 61ms/step - loss: 0.2527 - accuracy: 0.9366\n",
            "Epoch 11/20\n",
            "532/532 [==============================] - 32s 61ms/step - loss: 0.2598 - accuracy: 0.9354\n",
            "Epoch 12/20\n",
            "532/532 [==============================] - 32s 61ms/step - loss: 0.2276 - accuracy: 0.9427\n",
            "Epoch 13/20\n",
            "532/532 [==============================] - 33s 61ms/step - loss: 0.2427 - accuracy: 0.9389\n",
            "Epoch 14/20\n",
            "532/532 [==============================] - 32s 61ms/step - loss: 0.2179 - accuracy: 0.9454\n",
            "Epoch 15/20\n",
            "532/532 [==============================] - 32s 60ms/step - loss: 0.1993 - accuracy: 0.9505\n",
            "Epoch 16/20\n",
            "532/532 [==============================] - 32s 61ms/step - loss: 0.2248 - accuracy: 0.9435\n",
            "Epoch 17/20\n",
            "532/532 [==============================] - 33s 61ms/step - loss: 0.2129 - accuracy: 0.9468\n",
            "Epoch 18/20\n",
            "532/532 [==============================] - 33s 61ms/step - loss: 0.2102 - accuracy: 0.9473\n",
            "Epoch 19/20\n",
            "532/532 [==============================] - 32s 60ms/step - loss: 0.1948 - accuracy: 0.9518\n",
            "Epoch 20/20\n",
            "532/532 [==============================] - 32s 60ms/step - loss: 0.1863 - accuracy: 0.9540\n",
            "0.49867334905660377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2DGIwWMGi6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e93b4d66-44b6-461c-bafe-b33ffd9195bf"
      },
      "source": [
        "def evaluate(seq_in):\n",
        "  attention_plot = np.zeros((n_timesteps_in, n_timesteps_in))\n",
        "  print ('attention_plot shape: (n_timesteps_in, n_timesteps_in) {}'.format(attention_plot.shape))\n",
        "\n",
        "  #sequence = [7, 9, 8, 5]\n",
        "  #sequence = one_hot_encode(seq_in,n_features)\n",
        "  encoder_inputs = array(seq_in).reshape(1,n_timesteps_in,n_features)\n",
        "  \n",
        "  encoder_inputs = tf.convert_to_tensor(encoder_inputs,dtype=tf.float32)\n",
        "  print ('Encoder input shape: (batch size, sequence length, n_features) {}'.format(encoder_inputs.shape))\n",
        "\n",
        "\n",
        "  encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "  print ('Encoder output shape: (batch size, sequence length, latentSpaceDimension) {}'.format(encoder_outputs.shape))\n",
        "  print ('Encoder Hidden state shape: (batch size, latentSpaceDimension) {}'.format(state_h.shape))\n",
        "  print ('Encoder Cell state shape: (batch size, latentSpaceDimension) {}'.format(state_c.shape))\n",
        "  # initial context vector is the states of the encoder\n",
        "  states = [state_h, state_c]\n",
        "  \n",
        "  # Set up the attention layer\n",
        "  #attention= BahdanauAttention(latentSpaceDimension)\n",
        "\n",
        "\n",
        "  # Set up the decoder layers\n",
        "  #decoder_inputs = Input(shape=(1, (n_features+latentSpaceDimension)))\n",
        "  #decoder_lstm = LSTM(latentSpaceDimension,  return_state=True, name='decoder_lstm')\n",
        "  #decoder_dense = Dense(n_features, activation='softmax',  name='decoder_dense')\n",
        "\n",
        "  all_outputs = []\n",
        "\n",
        "  #INIT DECODER\n",
        "  # Prepare decoder input data that just contains the start character 0\n",
        "  # Note that we made it a constant one-hot-encoded in the model\n",
        "  # that is, [1 0 0 0 0 0 0 0 0 0] is the first input for each loop\n",
        "  decoder_input_data = np.zeros((1, 1, n_features))\n",
        "  decoder_input_data[:, 0, 0] = 1 \n",
        "  # that is, [1 0 0 0 0 0 0 0 0 0] is the first input for each loop\n",
        "  inputs = decoder_input_data\n",
        "  #initial hiiden state\n",
        "  decoder_outputs = state_h\n",
        "\n",
        "  print('initial decoder inputs: ', inputs.shape)\n",
        "\n",
        "  # decoder will only process one timestep at a time.\n",
        "  for t in range(n_timesteps_in):\n",
        "\n",
        "      # pay attention\n",
        "      context_vector, attention_weights=attention(decoder_outputs, encoder_outputs)\n",
        "\n",
        "\n",
        "\n",
        "      print(\"Attention context_vector: (batch size, units) {}\".format(context_vector.shape))\n",
        "      print(\"Attention weights : (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))\n",
        "\n",
        "      # storing the attention weights to plot later on\n",
        "      attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "      attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "      \n",
        "      decoder_outputs=tf.expand_dims(decoder_outputs, 1)\n",
        "      print('decoder_outputs: (batch_size, 1, latentSpaceDimension) ', decoder_outputs.shape )\n",
        "\n",
        "      context_vector = tf.expand_dims(context_vector, 1)\n",
        "      print('Reshaped context_vector: ', context_vector.shape )\n",
        "      inputs = tf.concat([context_vector, inputs], axis=-1)\n",
        "      #inputs = tf.concat([context_vector, inputs], axis=-1)\n",
        "      print('After concat inputs: (batch_size, 1, n_features + hidden_size): ',inputs.shape )\n",
        "\n",
        "      # passing the concatenated vector to the LSTM\n",
        "      # Run the decoder on one timestep\n",
        "      decoder_outputs, state_h, state_c = decoder_lstm(inputs,\n",
        "                                              initial_state=states)\n",
        "      #decoder_outputs = tf.reshape(decoder_outputs, (-1, decoder_outputs.shape[2]))\n",
        "    \n",
        "      outputs = decoder_dense(decoder_outputs)\n",
        "      # Store the current prediction (we will concatenate all predictions later)\n",
        "      outputs = tf.expand_dims(outputs, 1)\n",
        "      all_outputs.append(outputs)\n",
        "      # Reinject the outputs as inputs for the next loop iteration\n",
        "      # as well as update the states\n",
        "      inputs = outputs\n",
        "      states = [state_h, state_c]\n",
        "\n",
        "\n",
        "\n",
        "  # Concatenate all predictions such as [batch_size, timesteps, features]\n",
        "  decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
        "  seq_out=one_hot_decode(decoder_outputs[0])\n",
        "  \n",
        "  return seq_in, seq_out, attention_plot\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 63.8 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7TTvlLmJrkJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8faf979a-3f16-48b6-9257-13b5122789e7"
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sequence, predicted_sequence):\n",
        "  fig = plt.figure(figsize=(8,8))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sequence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sequence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 10.3 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pfe8eniJRoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71d5790c-5c85-4db1-ee0d-2b5bf08a4743"
      },
      "source": [
        "def translate(seq_in):\n",
        "  seq_in, seq_out, attention_plot = evaluate(seq_in)\n",
        "\n",
        "  print('Input: %s' % (seq_in))\n",
        "  print('Predicted translation: {}'.format(seq_out))\n",
        "\n",
        "  attention_plot = attention_plot[:len(seq_out), :len(seq_in)]\n",
        "  plot_attention(attention_plot, seq_in, seq_out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 3.59 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZgMQZduJ2Mi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "outputId": "cc422db4-5657-40e5-a5b8-1c3357eca2ac"
      },
      "source": [
        "#translate([1, 2, 3 ,4,5,6,7,8,9,1,2,3,4,5,7,6])\n",
        "translate([1, 2, 3 ,4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attention_plot shape: (n_timesteps_in, n_timesteps_in) (4, 4)\n",
            "Encoder input shape: (batch size, sequence length, n_features) (1, 4, 10)\n",
            "Encoder output shape: (batch size, sequence length, latentSpaceDimension) (1, 4, 16)\n",
            "Encoder Hidden state shape: (batch size, latentSpaceDimension) (1, 16)\n",
            "Encoder Cell state shape: (batch size, latentSpaceDimension) (1, 16)\n",
            "initial decoder inputs:  (1, 1, 10)\n",
            "Attention context_vector: (batch size, units) (1, 16)\n",
            "Attention weights : (batch_size, sequence_length, 1) (1, 4, 1)\n",
            "decoder_outputs: (batch_size, 1, latentSpaceDimension)  (1, 1, 16)\n",
            "Reshaped context_vector:  (1, 1, 16)\n",
            "After concat inputs: (batch_size, 1, n_features + hidden_size):  (1, 1, 26)\n",
            "Attention context_vector: (batch size, units) (1, 16)\n",
            "Attention weights : (batch_size, sequence_length, 1) (1, 4, 1)\n",
            "decoder_outputs: (batch_size, 1, latentSpaceDimension)  (1, 1, 16)\n",
            "Reshaped context_vector:  (1, 1, 16)\n",
            "After concat inputs: (batch_size, 1, n_features + hidden_size):  (1, 1, 26)\n",
            "Attention context_vector: (batch size, units) (1, 16)\n",
            "Attention weights : (batch_size, sequence_length, 1) (1, 4, 1)\n",
            "decoder_outputs: (batch_size, 1, latentSpaceDimension)  (1, 1, 16)\n",
            "Reshaped context_vector:  (1, 1, 16)\n",
            "After concat inputs: (batch_size, 1, n_features + hidden_size):  (1, 1, 26)\n",
            "Attention context_vector: (batch size, units) (1, 16)\n",
            "Attention weights : (batch_size, sequence_length, 1) (1, 4, 1)\n",
            "decoder_outputs: (batch_size, 1, latentSpaceDimension)  (1, 1, 16)\n",
            "Reshaped context_vector:  (1, 1, 16)\n",
            "After concat inputs: (batch_size, 1, n_features + hidden_size):  (1, 1, 26)\n",
            "Input: [1, 2, 3, 4]\n",
            "Predicted translation: [4, 3, 2, 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "time: 176 ms\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}