{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "final_code_partB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxtVFuUo5ske"
      },
      "source": [
        "%pip install wandb -q\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lobfPF7UpLBV"
      },
      "source": [
        "# Essentials\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import Adam\n",
        "from keras.applications import InceptionV3, ResNet50, InceptionResNetV2, Xception\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Flatten, Conv2D, BatchNormalization, Dropout, MaxPooling2D, Activation\n",
        "from keras.callbacks import  Callback, EarlyStopping\n",
        "\n",
        "import random\n",
        "import imageio\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "random.seed(42)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiBTYiP49zVA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "253980ec-cb2c-441f-be19-422fa6c060db"
      },
      "source": [
        "# Fetch the dataset form Github\n",
        "!git clone https://github.com/borate267/inaturalist-dataset.git"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'inaturalist-dataset' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDWjoSeTSqX3"
      },
      "source": [
        "# Define the labels for the Simpsons characters we're detecting\n",
        "class_names = {0:'Amphibia', 1:'Animalia', 2:'Arachnida',3: 'Aves',4: 'Fungi',\n",
        "              5: 'Insecta', 6:'Mammalia', 7:'Mollusca', 8:'Plantae',9: 'Reptilia'}\n",
        "num_classes = 10\n",
        "img_size = 224\n",
        "dir1 = 'inaturalist-dataset/train'\n",
        "dir2 = 'inaturalist-dataset/val'\n",
        "\n",
        "import random\n",
        "\n",
        "# Load training data\n",
        "X_train = []\n",
        "y_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for label, name in class_names.items():\n",
        "\n",
        "   list_images1 = os.listdir(dir1+'/'+name)\n",
        "   list_images2 = os.listdir(dir2+'/'+name)\n",
        "\n",
        "   for image_name in list_images1:\n",
        "       image = imageio.imread(dir1+'/'+name+'/'+image_name)\n",
        "       if np.ndim(image) == 3:\n",
        "          X_train.append(cv2.resize(image, (img_size,img_size)))\n",
        "          y_train.append(label)\n",
        "   \n",
        "   for image_name in list_images2:\n",
        "       image = imageio.imread(dir2+'/'+name+'/'+image_name)\n",
        "       if np.ndim(image) == 3:\n",
        "          X_test.append(cv2.resize(image, (img_size,img_size)))\n",
        "          y_test.append(label)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRyyf8imr6o3"
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Normalize the data\n",
        "X_train = X_train/255.0\n",
        "X_test = X_test/255.0\n",
        "\n",
        "# One hot encode the labels \n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv9V0KIA0cMv"
      },
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes', \n",
        "    'metric': {\n",
        "      'name': 'accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "        \n",
        "        'freeze_before' : {\n",
        "            'values': ['50','70','100']\n",
        "        },\n",
        "       \n",
        "       # 'models' :{\n",
        "        #    'values' : ['IV3','IRNV2', 'RN50', 'XCP']\n",
        "       # },\n",
        "        'dropout': {\n",
        "            'values': [0, 0.2, 0.4]\n",
        "        },     \n",
        "        'batch_size': {\n",
        "            'values': [32, 64]\n",
        "        },\n",
        "        'num_dense':{\n",
        "            'values': [64, 128, 256, 512]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXOtqavZ79Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5e9dcf5-6e2f-4d16-f453-079e8859ffdc"
      },
      "source": [
        "# Initialize a new sweep\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, entity=\"bharatik\", project=\"cs6910assignment2\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: ywzvoorq\n",
            "Sweep URL: https://wandb.ai/bharatik/cs6910assignment2/sweeps/ywzvoorq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48Wdt0Cz3VFb"
      },
      "source": [
        "input_shape = (224,224,3)\n",
        "\n",
        "# Comment the next line if you want to sweep over different models\n",
        "base_model =  InceptionResNetV2(input_shape = input_shape, include_top = False, weights = 'imagenet')\n",
        "\n",
        "def train():\n",
        "    \n",
        "    config_defaults = {\n",
        "        'freeze_before' : 50,\n",
        "        #'models' : 'IV3',\n",
        "        'dropout': 0.2,\n",
        "        'batch_size': 64,\n",
        "        'num_dense': 256,\n",
        "        'num_classes': 10,\n",
        "        'epochs' : 5\n",
        "    }\n",
        "\n",
        "     # Initialize a new wandb run\n",
        "    wandb.init(config=config_defaults)\n",
        "    \n",
        "    config = wandb.config\n",
        "    wandb.run.name = 'model_IncResV2_num_dense_'+ str(config.num_dense)+'_bs_'+str(config.batch_size)\n",
        "\n",
        "    \n",
        "\n",
        "    # Defining models\n",
        "  #  if config.models == 'IV3':\n",
        "   #     base_model =  InceptionV3(input_shape = input_shape, include_top = False, weights = 'imagenet')\n",
        "   # elif config.models == 'IRNV2':\n",
        "    #    base_model =  InceptionResNetV2(input_shape = input_shape, include_top = False, weights = 'imagenet')\n",
        "    #elif config.models == 'RN50':\n",
        "    #    base_model =  ResNet50(input_shape = input_shape, include_top = False, weights = 'imagenet')\n",
        "    #elif config.models == 'XCP':\n",
        "     #   base_model =  Xception(input_shape = input_shape, include_top = False, weights = 'imagenet')\n",
        "\n",
        "\n",
        "    base_model.trainable = False\n",
        "\n",
        "    stack_model = Sequential()\n",
        "    stack_model.add(base_model)\n",
        "    stack_model.add(Flatten())\n",
        "    stack_model.add(Dense(config.num_dense, activation='relu'))\n",
        "    stack_model.add(Dense(config.num_classes, activation='softmax'))\n",
        "    \n",
        "    final_model = stack_model\n",
        "    final_model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "\n",
        "    \n",
        "    #model.fit( datagen.flow(X_train, y_train, batch_size = config.batch_size), steps_per_epoch=len(X_train)/32, epochs=config.epochs,\n",
        "                       # validation_data=(X_val, y_val), callbacks = [WandbCallback()] )\n",
        "    \n",
        "    final_model.fit(\n",
        "        x = X_train,\n",
        "        y = y_train,\n",
        "        batch_size = config.batch_size,\n",
        "        epochs = config.epochs,\n",
        "        verbose = 1,\n",
        "        validation_data= (X_test, y_test),\n",
        "        callbacks = [WandbCallback(),keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
        "    )\n",
        "\n",
        "    ############  Fine tuning the model\n",
        "\n",
        "    base_model.trainable = True\n",
        "\n",
        "    # Freeze layers\n",
        "    freeze_point = len(base_model.layers) - config.freeze_before\n",
        "    for layer in base_model.layers[:freeze_point]:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    final_model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "\n",
        "    final_model.fit(\n",
        "        x = X_train,\n",
        "        y = y_train,\n",
        "        batch_size = config.batch_size,\n",
        "        epochs = 7,\n",
        "        verbose = 1,\n",
        "        validation_data= (X_test, y_test),\n",
        "        callbacks = [WandbCallback(),keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
        "    )\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7fONqu1L3ye"
      },
      "source": [
        "wandb.agent('ixzbgw3r',train, count = 1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}