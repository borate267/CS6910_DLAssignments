{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "final_code_partA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6a1eb5aa89ab4deebf8f200238054f88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2e5b55bec8534a9e8b2ab40379240c70",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c45c3ba7dabf40089e448bb7efc0ad7a",
              "IPY_MODEL_8eaa99fd1f4d4c40912decd194e29356"
            ]
          }
        },
        "2e5b55bec8534a9e8b2ab40379240c70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c45c3ba7dabf40089e448bb7efc0ad7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_1b17e895f07643a296babeeb77e09282",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.42MB of 0.42MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58080b245c934565baa6e751b798a2ed"
          }
        },
        "8eaa99fd1f4d4c40912decd194e29356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fbab91c8c0a045be88f9a0163ad0119a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c5d98e32d8041809387e15f57793882"
          }
        },
        "1b17e895f07643a296babeeb77e09282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58080b245c934565baa6e751b798a2ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fbab91c8c0a045be88f9a0163ad0119a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c5d98e32d8041809387e15f57793882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrXSX4MjxsY2"
      },
      "source": [
        "# Part A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aATW_9CRxiIg"
      },
      "source": [
        "This section contains implementation specifics of building a CNN based image classifier using the iNaturalist dataset.\n",
        "\n",
        "The Architecture:\n",
        "1.   Five convolution layers with each layer followed by a \n",
        "ReLU activation and a max pooling layer.\n",
        "2.   One dense layer \n",
        "3.   One output layer containing 10 neurons (1 for each of the 10 classes). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYiM_Whbx0pu"
      },
      "source": [
        "Import essential libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "DMMDN6JraJ5S"
      },
      "source": [
        "# Essentials\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Dense, Flatten, Conv2D, BatchNormalization, Dropout, MaxPooling2D, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras import callbacks\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, Callback, EarlyStopping\n",
        "import random\n",
        "import imageio\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "random.seed(42)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0m3yWmVgaJ5Y"
      },
      "source": [
        "# WandB – Install the W&B library\n",
        "%pip install wandb -q\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q2IlLNHxv5u"
      },
      "source": [
        "Fetch dataset from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prsXWfw8b9Pr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dcaaa31-4d87-4334-89ee-e10a4a6528eb"
      },
      "source": [
        "# Fetch the dataset form Github\n",
        "!git clone https://github.com/borate267/inaturalist-dataset.git"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'inaturalist-dataset' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ-6pgCvx5Kv"
      },
      "source": [
        "Read the training and validation images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LphhtX-0aJ5d"
      },
      "source": [
        "# Define the labels for the Simpsons characters we're detecting\n",
        "class_names = {0:'Amphibia', 1:'Animalia', 2:'Arachnida',3: 'Aves',4: 'Fungi',\n",
        "              5: 'Insecta', 6:'Mammalia', 7:'Mollusca', 8:'Plantae',9: 'Reptilia'}\n",
        "num_classes = 10\n",
        "img_size = 128\n",
        "dir = 'inaturalist-dataset/train'\n",
        "\n",
        "import random\n",
        "\n",
        "# Load training data\n",
        "X_train = []\n",
        "y_train = []\n",
        "for label, name in class_names.items():\n",
        "   list_images = os.listdir(dir+'/'+name)\n",
        "   for image_name in list_images:\n",
        "       image = imageio.imread(dir+'/'+name+'/'+image_name)\n",
        "       if np.ndim(image) == 3:\n",
        "          X_train.append(cv2.resize(image, (img_size,img_size)))\n",
        "          y_train.append(label)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzIqdJNLx77-"
      },
      "source": [
        "Shuffle the images and then retain 10% as validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE0f5kewFTpG"
      },
      "source": [
        "leng = np.shape(X_train)\n",
        "arr = np.arange(leng[0])\n",
        "np.random.shuffle(arr)\n",
        "X_train_shuf = []\n",
        "y_train_shuf = []\n",
        "X_val_shuf = []\n",
        "y_val_shuf = []\n",
        "\n",
        "for i in range(leng[0]):\n",
        "  if i <= 9000:\n",
        "    X_train_shuf.append(X_train[arr[i]])\n",
        "    y_train_shuf.append(y_train[arr[i]])\n",
        "  else:\n",
        "    X_val_shuf.append(X_train[arr[i]])\n",
        "    y_val_shuf.append(y_train[arr[i]])\n",
        "\n",
        "X_train = np.array(X_train_shuf)\n",
        "y_train = np.array(y_train_shuf)\n",
        "X_val = np.array(X_val_shuf)\n",
        "y_val = np.array(y_val_shuf)\n",
        "\n",
        "# Normalize the data\n",
        "X_train = X_train/255.0\n",
        "X_val = X_val/255.0\n",
        "\n",
        "# One hot encode the labels \n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_val = np_utils.to_categorical(y_val, num_classes)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMVb9Sj6yD83"
      },
      "source": [
        "Configure the sweep hyperparameter dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdaHO-3M8ly3"
      },
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes', \n",
        "    'metric': {\n",
        "      'name': 'accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "        'kernel_size':{\n",
        "            'values': [[(3,3),(3,3),(3,3),(3,3),(3,3)], [(3,3),(5,5),(5,5),(7,7),(7,7)], [(7,7),(7,7),(5,5),(5,5),(3,3)], [(3,3),(5,5),(7,7),(9,9),(11,11)] ]\n",
        "        },\n",
        "        'weight_decay': {\n",
        "            'values': [0, 0.0005, 0.005]\n",
        "        },\n",
        "        'dropout': {\n",
        "            'values': [0, 0.2, 0.4]\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            'values': [1e-3, 1e-4]\n",
        "        },\n",
        "        'activation': {\n",
        "            'values': ['relu', 'elu', 'selu']\n",
        "        },\n",
        "        'batch_norm':{\n",
        "            'values': ['true','false']\n",
        "        },\n",
        "        #'filt_org':{\n",
        "        #    'values': [[32,32,32,32,32],[32,64,64,128,128],[128,128,64,64,32],[32,64,128,256,512]]\n",
        "        #},\n",
        "        'filt_org' :{\n",
        "            'values': ['standard','double', 'half']\n",
        "        },\n",
        "        'conv_layer_size':{\n",
        "            'values' : [16, 32]\n",
        "        },\n",
        "        'data_augment': {\n",
        "            'values': ['true','false']\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [32, 64]\n",
        "        },\n",
        "        'num_dense':{\n",
        "            'values': [64, 128, 256, 512]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll_zFhpaU6cu"
      },
      "source": [
        " Initialize the Sweep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdc7RBBaU0F3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d11807a-5763-444d-a5bf-1965f9d1a0e3"
      },
      "source": [
        "# Initialize a new sweep\n",
        "sweep_id = wandb.sweep(sweep_config, entity=\"bharatik\", project=\"cs6910assignment2\")"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: iieb3ba8\n",
            "Sweep URL: https://wandb.ai/bharatik/cs6910assignment2/sweeps/iieb3ba8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aIhxl7glaJ5k"
      },
      "source": [
        "def train():\n",
        "    \n",
        "    config_defaults = {\n",
        "        'kernel_size': [(3,3),(3,3),(3,3),(3,3),(3,3)],\n",
        "        'weight_decay': 0.005,\n",
        "        'dropout': 0.2,\n",
        "        'learning_rate': 1e-3,\n",
        "        'activation': 'relu',\n",
        "        'batch_size': 64,\n",
        "        'epochs': 10,\n",
        "        'batch_norm': 'true',\n",
        "        'filt_org' : 'standard',\n",
        "        'conv_layer_size' : 16,\n",
        "        'data_augment': 'true',\n",
        "        'num_dense': 256,\n",
        "        'seed': 42,\n",
        "        'num_classes': 10\n",
        "    }\n",
        "\n",
        "    # Initialize a new wandb run\n",
        "    wandb.init(config=config_defaults)\n",
        "    \n",
        "    # Config is a variable that holds and saves hyperparameters and inputs\n",
        "    config = wandb.config\n",
        "    wandb.run.name = 'num_dense_'+ str(config.num_dense)+'_bs_'+str(config.batch_size)+'_ac_'+ config.activation\n",
        "    \n",
        "    # Determine input shape\n",
        "    input_shape = (img_size, img_size , 3)\n",
        "    \n",
        "    # Define the model architecture\n",
        "    model = Sequential()\n",
        "    \n",
        "    # ficing conv layer sizeƒ\n",
        "\n",
        "    dummy = config.conv_layer_size\n",
        "    filter = []\n",
        "    for i in range(5):\n",
        "      if config.filt_org == 'standard':\n",
        "        filter.append(dummy)\n",
        "      elif config.filt_org == \"double\":\n",
        "        filter.append( dummy*(2**i) )\n",
        "      elif config.filt_org == \"half\":\n",
        "        filter.append( dummy*((0.5)**i) )\n",
        "\n",
        "    # Layer one\n",
        "    model.add(Conv2D(filters = filter[0], kernel_size = config.kernel_size[0],padding = 'same', \n",
        "                    input_shape = input_shape, kernel_regularizer=regularizers.l2(config.weight_decay)))\n",
        "\n",
        "    if config.activation == \"relu\":\n",
        "        model.add(Activation('relu'))\n",
        "    elif config.activation == \"elu\":\n",
        "        model.add(Activation('elu'))\n",
        "    elif config.activation == \"selu\":\n",
        "        model.add(Activation('selu'))\n",
        "\n",
        "    if config.batch_norm == 'True':\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(config.dropout))\n",
        "\n",
        "\n",
        "    # Layer two\n",
        "    model.add(Conv2D(filters = filter[1], kernel_size = config.kernel_size[1], padding = 'same', \n",
        "                    input_shape = input_shape, kernel_regularizer=regularizers.l2(config.weight_decay)))\n",
        "\n",
        "    if config.activation == \"relu\":\n",
        "        model.add(Activation('relu'))\n",
        "    elif config.activation == \"elu\":\n",
        "        model.add(Activation('elu'))\n",
        "    elif config.activation == \"selu\":\n",
        "        model.add(Activation('selu'))\n",
        "\n",
        "    if config.batch_norm == 'True':\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(config.dropout))\n",
        "\n",
        "\n",
        "    # Layer three\n",
        "    model.add(Conv2D(filters = filter[2], kernel_size = config.kernel_size[2], padding = 'same', \n",
        "                    input_shape = input_shape, kernel_regularizer=regularizers.l2(config.weight_decay)))\n",
        "\n",
        "    if config.activation == \"relu\":\n",
        "        model.add(Activation('relu'))\n",
        "    elif config.activation == \"elu\":\n",
        "        model.add(Activation('elu'))\n",
        "    elif config.activation == \"selu\":\n",
        "        model.add(Activation('selu'))\n",
        "\n",
        "    if config.batch_norm == 'True':\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(config.dropout))\n",
        "\n",
        "    # Layer four\n",
        "    model.add(Conv2D(filters = filter[3], kernel_size = config.kernel_size[3], padding = 'same', \n",
        "                    input_shape = input_shape, kernel_regularizer=regularizers.l2(config.weight_decay)))\n",
        "\n",
        "    if config.activation == \"relu\":\n",
        "        model.add(Activation('relu'))\n",
        "    elif config.activation == \"elu\":\n",
        "        model.add(Activation('elu'))\n",
        "    elif config.activation == \"selu\":\n",
        "        model.add(Activation('selu'))\n",
        "\n",
        "    if config.batch_norm == 'True':\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(config.dropout))\n",
        "    \n",
        "\n",
        "    # Layer five\n",
        "    model.add(Conv2D(filters = filter[4], kernel_size = config.kernel_size[4], padding = 'same', \n",
        "                    input_shape = input_shape, kernel_regularizer=regularizers.l2(config.weight_decay)))\n",
        "\n",
        "    if config.activation == \"relu\":\n",
        "        model.add(Activation('relu'))\n",
        "    elif config.activation == \"elu\":\n",
        "        model.add(Activation('elu'))\n",
        "    elif config.activation == \"selu\":\n",
        "        model.add(Activation('selu'))\n",
        "\n",
        "    if config.batch_norm == 'True':\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # FC layer\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(config.num_dense, activation = config.activation, kernel_regularizer = regularizers.l2(config.weight_decay)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(num_classes, activation = \"softmax\"))\n",
        "\n",
        "    # Define the optimizer\n",
        "    #optimizer = Adam(lr=config.learning_rate, beta_1=0.9, beta_2=0.999)\n",
        "    \n",
        "    model.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics=['accuracy'])\n",
        "\n",
        "    #data augmentation\n",
        "    if config.data_augment == 'true':\n",
        "        datagen = ImageDataGenerator(\n",
        "            featurewise_center=True,  # set input mean to 0 over the dataset\n",
        "            samplewise_center=True,  # set each sample mean to 0\n",
        "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "            samplewise_std_normalization=False,  # divide each input by its std\n",
        "            zca_whitening=False,  # apply ZCA whitening\n",
        "            rotation_range=45,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "            width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "            horizontal_flip=True,  # randomly flip images\n",
        "            vertical_flip=False  # randomly flip images\n",
        "        )\n",
        "    else:\n",
        "        datagen = ImageDataGenerator(rescale = 1.0)\n",
        "\n",
        "    datagen.fit(X_train)\n",
        "    \n",
        "    #model.fit( datagen.flow(X_train, y_train, batch_size = config.batch_size), steps_per_epoch=len(X_train)/32, epochs=config.epochs,\n",
        "                       # validation_data=(X_val, y_val), callbacks = [WandbCallback()] )\n",
        "    \n",
        "    model.fit(\n",
        "        x = X_train,\n",
        "        y = y_train,\n",
        "        batch_size = config.batch_size,\n",
        "        epochs = config.epochs,\n",
        "        verbose = 1,\n",
        "        validation_data= (X_val, y_val),\n",
        "        callbacks = [WandbCallback(),keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
        "    )\n",
        "    \n",
        "\n",
        "    \n",
        "    "
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVxXIXXTyOLC"
      },
      "source": [
        "Run the sweep agent for 100 runs or more"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gD9qhA9yOYs"
      },
      "source": [
        "# Initialize a new sweep\n",
        "# Arguments:\n",
        "#     – sweep_id: the sweep_id to run - this was returned above by wandb.sweep()\n",
        "#     – function: function that defines your model architecture and trains it\n",
        "wandb.agent('th7cm1co', train, count = 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAMixcayyU_v"
      },
      "source": [
        "Testing ground"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVfpq39xBZin"
      },
      "source": [
        " # Load testing dataset\n",
        "\n",
        "dir = \"inaturalist-dataset/val\"\n",
        "X_test = []\n",
        "y_test = []\n",
        "for label, name in class_names.items():\n",
        "   list_images = os.listdir(dir+'/'+name)\n",
        "   for image_name in list_images:\n",
        "       image = imageio.imread(dir+'/'+name+'/'+image_name)\n",
        "       if np.ndim(image) == 3:\n",
        "          X_test.append(cv2.resize(image, (img_size,img_size)))\n",
        "          y_test.append(label)\n",
        "\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhZzfutMyZfu"
      },
      "source": [
        "Shuffle and pre-process the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rUww9Pzn-Yp"
      },
      "source": [
        "leng = np.shape(X_test)\n",
        "arr = np.arange(leng[0])\n",
        "np.random.shuffle(arr)\n",
        "X_test_shuf = []\n",
        "y_test_shuf = []\n",
        "\n",
        "for i in range(leng[0]):\n",
        "  X_test_shuf.append(X_test[arr[i]])\n",
        "  y_test_shuf.append(y_test[arr[i]])\n",
        "\n",
        "X_test = np.array(X_test_shuf)\n",
        "y_test = np.array(y_test_shuf)\n",
        "\n",
        "# Normalize the data\n",
        "X_test = X_test/255.0\n",
        "\n",
        "# One hot encode the labels (neural nets only like numbers)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1pCRAFXygyX"
      },
      "source": [
        "Testing accuracy and losses are computed by calling the following function using the best set of hyperparameters obtained by sweeping over 148 runs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwYDogvYlaPm",
        "outputId": "7dac6da5-096a-4c06-ae49-c04085d4263c"
      },
      "source": [
        "def test():\n",
        "    \n",
        "    # BEST HYPERPARAMETERS AFTER 148 SWEEPS\n",
        "    best_kernel_size = [(3,3),(5,5),(5,5),(7,7),(7,7)]\n",
        "    best_weight_decay = 0\n",
        "    best_dropout = 0\n",
        "    best_learning_rate = 1e-3\n",
        "    best_activation = 'elu'\n",
        "    best_batch_size = 64\n",
        "    best_batch_norm = 'true'\n",
        "    best_filt_org = 'standard'\n",
        "    best_conv_layer_size = 32\n",
        "    best_data_augment = 'false'\n",
        "    best_num_dense = 256\n",
        "    \n",
        "    # Determine input shape\n",
        "    input_shape = (img_size, img_size, 3)\n",
        "    \n",
        "    # Define the model architecture\n",
        "    model = Sequential()\n",
        "    \n",
        "    # fixing conv layer size\n",
        "\n",
        "    filter = []\n",
        "    for i in range(5):\n",
        "        filter.append(best_conv_layer_size)\n",
        "      \n",
        "    # Layer one\n",
        "    model.add(Conv2D(filters = filter[0], kernel_size = best_kernel_size[0],padding = 'same', \n",
        "                    input_shape = input_shape, kernel_regularizer=regularizers.l2(best_weight_decay)))\n",
        "    model.add(Activation('elu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(best_dropout))\n",
        "\n",
        "\n",
        "    # Layer two\n",
        "    model.add(Conv2D(filters = filter[1], kernel_size = best_kernel_size[1],padding = 'same', \n",
        "                    input_shape = input_shape, kernel_regularizer=regularizers.l2(best_weight_decay)))\n",
        "    model.add(Activation('elu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(best_dropout))\n",
        "\n",
        "\n",
        "    # Layer three\n",
        "    model.add(Conv2D(filters = filter[2], kernel_size = best_kernel_size[2],padding = 'same', \n",
        "                    input_shape = input_shape, kernel_regularizer=regularizers.l2(best_weight_decay)))\n",
        "    model.add(Activation('elu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(best_dropout))\n",
        "\n",
        "    # Layer four\n",
        "    model.add(Conv2D(filters = filter[3], kernel_size = best_kernel_size[3],padding = 'same', \n",
        "                    input_shape = input_shape, kernel_regularizer=regularizers.l2(best_weight_decay)))\n",
        "    model.add(Activation('elu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(best_dropout))\n",
        "    \n",
        "\n",
        "    # Layer five\n",
        "    model.add(Conv2D(filters = filter[4], kernel_size = best_kernel_size[4],padding = 'same', \n",
        "                    input_shape = input_shape, kernel_regularizer=regularizers.l2(best_weight_decay)))\n",
        "    model.add(Activation('elu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(best_dropout))\n",
        "\n",
        "    # FC layer\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(best_num_dense, activation = 'elu', kernel_regularizer = regularizers.l2(best_weight_decay)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(10, activation = \"softmax\"))\n",
        "\n",
        "    # Define the optimizer\n",
        "    optimizer = Adam(lr= best_learning_rate, beta_1=0.9, beta_2=0.999)\n",
        "    \n",
        "    model.compile(loss = \"categorical_crossentropy\", optimizer = optimizer, metrics=['accuracy'])\n",
        "\n",
        "    datagen = ImageDataGenerator(rescale = 1.0)\n",
        "    datagen.fit(X_train)\n",
        "    \n",
        "    model.fit(\n",
        "        x = X_train,\n",
        "        y = y_train,\n",
        "        batch_size = best_batch_size,\n",
        "        epochs = 10,\n",
        "        verbose = 1,\n",
        "        validation_data= (X_test, y_test),\n",
        "    )\n",
        "\n",
        "    y_pred = []\n",
        "\n",
        "    #for i in range(10):\n",
        "    class_ = class_names[0]\n",
        "    list_images = os.listdir('inaturalist-dataset/val/'+ class_)\n",
        "    n = random.randint(0,200)\n",
        "\n",
        "    # Read in a character image from the test dataset\n",
        "    image = imageio.imread('inaturalist-dataset/val/'+ class_+'/'+list_images[n])\n",
        "    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Resize image and normalize it\n",
        "    pic = cv2.resize(image, (128, 128)).astype('float32') / 255.\n",
        "          \n",
        "    # predictions for the class\n",
        "    prediction = model.predict(pic.reshape(1, 128, 128,3))[0]\n",
        "\n",
        "    # Get true name of the character\n",
        "    name = class_.split('_')[0].title()\n",
        "\n",
        "test()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "141/141 [==============================] - 7s 37ms/step - loss: 2.3310 - accuracy: 0.2324 - val_loss: 2.7761 - val_accuracy: 0.1290\n",
            "Epoch 2/10\n",
            "141/141 [==============================] - 5s 33ms/step - loss: 1.9647 - accuracy: 0.3047 - val_loss: 2.3764 - val_accuracy: 0.1640\n",
            "Epoch 3/10\n",
            "141/141 [==============================] - 5s 33ms/step - loss: 1.8720 - accuracy: 0.3448 - val_loss: 2.3369 - val_accuracy: 0.2055\n",
            "Epoch 4/10\n",
            "141/141 [==============================] - 5s 33ms/step - loss: 1.7823 - accuracy: 0.3733 - val_loss: 2.0268 - val_accuracy: 0.3110\n",
            "Epoch 5/10\n",
            "141/141 [==============================] - 5s 33ms/step - loss: 1.6608 - accuracy: 0.4135 - val_loss: 1.9794 - val_accuracy: 0.3385\n",
            "Epoch 6/10\n",
            "141/141 [==============================] - 5s 33ms/step - loss: 1.5337 - accuracy: 0.4722 - val_loss: 1.9854 - val_accuracy: 0.3480\n",
            "Epoch 7/10\n",
            "141/141 [==============================] - 5s 33ms/step - loss: 1.4050 - accuracy: 0.5173 - val_loss: 2.0110 - val_accuracy: 0.3360\n",
            "Epoch 8/10\n",
            "141/141 [==============================] - 5s 33ms/step - loss: 1.1808 - accuracy: 0.5981 - val_loss: 2.1530 - val_accuracy: 0.3450\n",
            "Epoch 9/10\n",
            "141/141 [==============================] - 5s 33ms/step - loss: 0.9405 - accuracy: 0.6860 - val_loss: 2.3716 - val_accuracy: 0.3400\n",
            "Epoch 10/10\n",
            "141/141 [==============================] - 5s 33ms/step - loss: 0.7115 - accuracy: 0.7666 - val_loss: 2.5759 - val_accuracy: 0.3350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619,
          "referenced_widgets": [
            "6a1eb5aa89ab4deebf8f200238054f88",
            "2e5b55bec8534a9e8b2ab40379240c70",
            "c45c3ba7dabf40089e448bb7efc0ad7a",
            "8eaa99fd1f4d4c40912decd194e29356",
            "1b17e895f07643a296babeeb77e09282",
            "58080b245c934565baa6e751b798a2ed",
            "fbab91c8c0a045be88f9a0163ad0119a",
            "8c5d98e32d8041809387e15f57793882"
          ]
        },
        "id": "uWB29xdQhAgA",
        "outputId": "3bf3483b-f4da-407e-a56a-93f251044ae4"
      },
      "source": [
        "wandb.init(project=\"cs6910assignment2\", entity=\"bharatik\")\n",
        "\n",
        "y_pred = []\n",
        "\n",
        " #for i in range(10):\n",
        "class_ = class_names[0]\n",
        "list_images = os.listdir('inaturalist-dataset/val/'+ class_)\n",
        "n = random.randint(0,200)\n",
        "\n",
        "# Read in a character image from the test dataset\n",
        "image = imageio.imread('inaturalist-dataset/val/'+ class_+'/'+list_images[n])\n",
        "img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Resize image and normalize it\n",
        "pic = cv2.resize(image, (128, 128)).astype('float32') / 255.\n",
        "      \n",
        "# predictions for the class\n",
        "prediction = model.predict(pic.reshape(1, 128, 128,3))[0]\n",
        "\n",
        "# Get true name of the character\n",
        "name = class_.split('_')[0].title()\n",
        "\n"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:jukq5k7b) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 12741<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a1eb5aa89ab4deebf8f200238054f88",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.42MB of 0.42MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210412_110804-jukq5k7b/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210412_110804-jukq5k7b/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>574</td></tr><tr><td>_timestamp</td><td>1618226261</td></tr><tr><td>_step</td><td>1</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>▁█</td></tr><tr><td>_timestamp</td><td>▁█</td></tr><tr><td>_step</td><td>▁█</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">num_dense_512_bs_64_ac_selu</strong>: <a href=\"https://wandb.ai/bharatik/cs6910assignment2/runs/jukq5k7b\" target=\"_blank\">https://wandb.ai/bharatik/cs6910assignment2/runs/jukq5k7b</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:jukq5k7b). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.25<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">num_dense_512_bs_64_ac_selu</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/bharatik/cs6910assignment2\" target=\"_blank\">https://wandb.ai/bharatik/cs6910assignment2</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/bharatik/cs6910assignment2/sweeps/th7cm1co\" target=\"_blank\">https://wandb.ai/bharatik/cs6910assignment2/sweeps/th7cm1co</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/bharatik/cs6910assignment2/runs/jukq5k7b\" target=\"_blank\">https://wandb.ai/bharatik/cs6910assignment2/runs/jukq5k7b</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210412_111752-jukq5k7b</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKxqztpCr-td"
      },
      "source": [
        "# Format predictions to string to overlay on image\n",
        "text = sorted(['{:s} : {:.1f}%'.format(class_names[k].split('_')[0].title(), 100*v) for k,v in enumerate(prediction)], \n",
        "    key=lambda x:float(x.split(':')[1].split('%')[0]), reverse=True)[:3]\n",
        "\n",
        "# Upscale image\n",
        "img = cv2.resize(img, (352, 352))\n",
        "\n",
        "# Create background to overlay text on\n",
        "cv2.rectangle(img, (0,260),(215,352),(255,255,255), -1)\n",
        "\n",
        "# Add text to image\n",
        "font = cv2.FONT_HERSHEY_DUPLEX\n",
        "cv2.putText(img, 'True Name : %s' % name, (10, 280), font, 0.7,(73,79,183), 2, cv2.LINE_AA)\n",
        "for k, t in enumerate(text):\n",
        "    cv2.putText(img, t, (10, 300+k*18), font, 0.65,(0,0,0), 2, cv2.LINE_AA)\n",
        "    \n",
        "# Add predicted image from test dataset with annotations to array\n",
        "y_pred.append(wandb.Image(img, caption=\"Actual: %s\" % name))    \n",
        "\n",
        "wandb.log({\"predictions\": y_pred})"
      ],
      "execution_count": 93,
      "outputs": []
    }
  ]
}